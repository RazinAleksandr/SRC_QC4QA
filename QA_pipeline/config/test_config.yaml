eval:
  model:
    name: "/raid/models/llama-7b-hf"
    load_in_8bit: true
    peft_model_id: /home/st-aleksandr-razin/workspace/SRC_QC4QA/artifacts/experiments/train-ptune-llama-Data_Science_and_Machine_Learning_class-7b-bs_16-lr_1e4-m_l_1280-m_p_l_768-num_toks_512-w_decay_0.1
    torch_dtype: fp16 # fp16/null
    device_map: cuda:1
    padding_side: left
  seed: 42
  batch_size: 16
  compute_metrics: true
  data:
    dataset_name: RazinAleks/SO-Python_QA-Data_Science_and_Machine_Learning_class
    max_prompt_length: 768
    split: "test"  
    use_title: true
    columns_to_save:
      - Question
      - Answer
      - Title # if use_title
      - Score
      - Users Score
  generate_config:
    do_sample: true
    max_new_tokens: 512
    no_repeat_ngram_size: 2
    top_k: 50
    top_p: 0.9
    use_cache: true
    num_return_sequences: 1
log_config:
  save_steps: 5
  dir: /home/st-aleksandr-razin/workspace/SRC_QC4QA/artifacts/tests/Data_Science_and_Machine_Learning_class
  file_name: test-p_tune_llama_filt_no_code-7b-max_prompt_length_768-Data_Science_and_Machine_Learning_class.csv

wandb_config:
  project: 'SRC_QC4QA'
  name: test-p_tune_llama_filt_no_code-7b-max_prompt_length_768-Data_Science_and_Machine_Learning_class.csv
  tags:
    - "SRC_QC4QA"
    - "test"