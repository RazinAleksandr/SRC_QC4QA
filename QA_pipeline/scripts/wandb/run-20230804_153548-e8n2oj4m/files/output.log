  0%|                                                                                                                                                                              | 0/650 [00:00<?, ?it/s]/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|▎                                                                                                                                                                   | 1/650 [00:25<4:33:44, 25.31s/it]

  0%|▌                                                                                                                                                                   | 2/650 [00:49<4:25:36, 24.59s/it]

  0%|▊                                                                                                                                                                   | 3/650 [01:13<4:22:52, 24.38s/it]
{'loss': 2.2886, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.05}

  1%|█                                                                                                                                                                   | 4/650 [01:38<4:23:22, 24.46s/it]


  1%|█▌                                                                                                                                                                  | 6/650 [02:27<4:23:07, 24.51s/it]

  1%|█▊                                                                                                                                                                  | 7/650 [02:51<4:21:48, 24.43s/it]

  1%|██                                                                                                                                                                  | 8/650 [03:15<4:21:06, 24.40s/it]

  1%|██▎                                                                                                                                                                 | 9/650 [03:39<4:18:53, 24.23s/it]

  2%|██▌                                                                                                                                                                | 10/650 [04:03<4:17:35, 24.15s/it]

  2%|██▊                                                                                                                                                                | 11/650 [04:28<4:19:04, 24.33s/it]

  2%|███                                                                                                                                                                | 12/650 [04:52<4:18:21, 24.30s/it]
{'loss': 2.3093, 'learning_rate': 4.999254056003963e-05, 'epoch': 0.18}


  2%|███▌                                                                                                                                                               | 14/650 [05:41<4:18:15, 24.36s/it]

  2%|███▊                                                                                                                                                               | 15/650 [06:05<4:17:11, 24.30s/it]

  2%|████                                                                                                                                                               | 16/650 [06:29<4:16:04, 24.23s/it]

  3%|████▎                                                                                                                                                              | 17/650 [06:54<4:16:33, 24.32s/it]
{'loss': 2.4206, 'learning_rate': 4.997016669161806e-05, 'epoch': 0.26}

  3%|████▌                                                                                                                                                              | 18/650 [07:18<4:17:12, 24.42s/it]

  3%|████▊                                                                                                                                                              | 19/650 [07:42<4:15:07, 24.26s/it]

  3%|█████                                                                                                                                                              | 20/650 [08:06<4:14:26, 24.23s/it]


  3%|█████▌                                                                                                                                                             | 22/650 [08:55<4:14:46, 24.34s/it]

  4%|█████▊                                                                                                                                                             | 23/650 [09:19<4:13:32, 24.26s/it]
{'loss': 2.3622, 'learning_rate': 4.992365042931752e-05, 'epoch': 0.35}


  4%|██████▎                                                                                                                                                            | 25/650 [10:09<4:15:59, 24.57s/it]

  4%|██████▌                                                                                                                                                            | 26/650 [10:33<4:13:24, 24.37s/it]

  4%|██████▊                                                                                                                                                            | 27/650 [10:57<4:12:42, 24.34s/it]

  4%|███████                                                                                                                                                            | 28/650 [11:22<4:12:53, 24.39s/it]

  4%|███████▎                                                                                                                                                           | 29/650 [11:47<4:15:33, 24.69s/it]

  5%|███████▌                                                                                                                                                           | 30/650 [12:12<4:15:32, 24.73s/it]
{'loss': 2.3074, 'learning_rate': 4.9842316440475475e-05, 'epoch': 0.46}

  5%|███████▊                                                                                                                                                           | 31/650 [12:37<4:14:33, 24.67s/it]

  5%|████████                                                                                                                                                           | 32/650 [13:00<4:11:31, 24.42s/it]

  5%|████████▎                                                                                                                                                          | 33/650 [13:25<4:10:33, 24.37s/it]




























 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 29/30 [01:42<00:03,  3.57s/it]

{'eval_loss': 2.3082401752471924, 'eval_runtime': 108.3603, 'eval_samples_per_second': 4.374, 'eval_steps_per_second': 0.277, 'epoch': 0.51}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  5%|████████▌                                                                                                                                                          | 34/650 [15:37<9:44:02, 56.89s/it]

  5%|████████▊                                                                                                                                                          | 35/650 [16:02<8:02:13, 47.05s/it]

  6%|█████████                                                                                                                                                          | 36/650 [16:26<6:51:52, 40.25s/it]

  6%|█████████▎                                                                                                                                                         | 37/650 [16:50<6:01:10, 35.35s/it]

  6%|█████████▌                                                                                                                                                         | 38/650 [17:14<5:27:51, 32.14s/it]
{'loss': 2.2655, 'learning_rate': 4.9713792638302145e-05, 'epoch': 0.58}


  6%|██████████                                                                                                                                                         | 40/650 [18:02<4:43:23, 27.87s/it]

  6%|██████████▎                                                                                                                                                        | 41/650 [18:26<4:31:17, 26.73s/it]

  6%|██████████▌                                                                                                                                                        | 42/650 [18:50<4:22:56, 25.95s/it]

  7%|██████████▊                                                                                                                                                        | 43/650 [19:15<4:17:11, 25.42s/it]
{'loss': 2.2271, 'learning_rate': 4.961427937122598e-05, 'epoch': 0.66}


  7%|███████████▎                                                                                                                                                       | 45/650 [20:03<4:09:05, 24.70s/it]
{'loss': 2.3099, 'learning_rate': 4.957035760813982e-05, 'epoch': 0.69}


  7%|███████████▊                                                                                                                                                       | 47/650 [20:50<4:02:34, 24.14s/it]

  7%|████████████                                                                                                                                                       | 48/650 [21:14<4:01:55, 24.11s/it]

  8%|████████████▎                                                                                                                                                      | 49/650 [21:38<4:01:53, 24.15s/it]
{'loss': 2.2509, 'learning_rate': 4.9475480211302583e-05, 'epoch': 0.75}

  8%|████████████▌                                                                                                                                                      | 50/650 [22:02<3:59:12, 23.92s/it]

  8%|████████████▊                                                                                                                                                      | 51/650 [22:25<3:56:56, 23.73s/it]

  8%|█████████████                                                                                                                                                      | 52/650 [22:49<3:57:56, 23.87s/it]


  8%|█████████████▌                                                                                                                                                     | 54/650 [23:37<3:56:50, 23.84s/it]
{'loss': 2.1303, 'learning_rate': 4.93437425335171e-05, 'epoch': 0.83}

  8%|█████████████▊                                                                                                                                                     | 55/650 [24:01<3:57:44, 23.97s/it]


  9%|██████████████▎                                                                                                                                                    | 57/650 [24:50<3:59:12, 24.20s/it]

  9%|██████████████▌                                                                                                                                                    | 58/650 [25:14<3:58:54, 24.21s/it]
{'loss': 2.4163, 'learning_rate': 4.9227888702567044e-05, 'epoch': 0.89}

  9%|██████████████▊                                                                                                                                                    | 59/650 [25:38<3:56:54, 24.05s/it]

  9%|███████████████                                                                                                                                                    | 60/650 [26:02<3:56:20, 24.03s/it]


 10%|███████████████▌                                                                                                                                                   | 62/650 [26:50<3:56:27, 24.13s/it]
{'loss': 2.2633, 'learning_rate': 4.910278151011458e-05, 'epoch': 0.95}
Aborted!
 10%|███████████████▌                                                                                                                                                   | 62/650 [26:52<4:14:53, 26.01s/it]