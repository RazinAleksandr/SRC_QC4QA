  0%|                                                                                                                                                                                                                            | 0/820 [00:00<?, ?it/s]/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|▎                                                                                                                                                                                                                 | 1/820 [00:25<5:47:08, 25.43s/it]

  0%|▌                                                                                                                                                                                                                 | 2/820 [00:49<5:38:37, 24.84s/it]

  0%|▊                                                                                                                                                                                                                 | 3/820 [01:13<5:33:11, 24.47s/it]

  0%|█                                                                                                                                                                                                                 | 4/820 [01:39<5:38:34, 24.90s/it]

  1%|█▎                                                                                                                                                                                                                | 5/820 [02:03<5:36:17, 24.76s/it]
{'loss': 2.4107, 'learning_rate': 5.555555555555556e-05, 'epoch': 0.06}

  1%|█▌                                                                                                                                                                                                                | 6/820 [02:28<5:34:20, 24.64s/it]


  1%|██                                                                                                                                                                                                                | 8/820 [03:15<5:26:28, 24.12s/it]

  1%|██▎                                                                                                                                                                                                               | 9/820 [03:40<5:25:50, 24.11s/it]

  1%|██▌                                                                                                                                                                                                              | 10/820 [04:04<5:24:59, 24.07s/it]

  1%|██▊                                                                                                                                                                                                              | 11/820 [04:27<5:23:55, 24.02s/it]
{'loss': 2.4879, 'learning_rate': 9.999849943136463e-05, 'epoch': 0.13}

  1%|███                                                                                                                                                                                                              | 12/820 [04:52<5:25:00, 24.13s/it]

  2%|███▎                                                                                                                                                                                                             | 13/820 [05:16<5:26:18, 24.26s/it]

  2%|███▌                                                                                                                                                                                                             | 14/820 [05:40<5:24:49, 24.18s/it]


  2%|████                                                                                                                                                                                                             | 16/820 [06:29<5:25:57, 24.33s/it]

  2%|████▎                                                                                                                                                                                                            | 17/820 [06:53<5:25:13, 24.30s/it]
{'loss': 2.3011, 'learning_rate': 9.99759927031559e-05, 'epoch': 0.21}

  2%|████▌                                                                                                                                                                                                            | 18/820 [07:18<5:26:28, 24.42s/it]

  2%|████▊                                                                                                                                                                                                            | 19/820 [07:43<5:25:47, 24.40s/it]

  2%|███▊                                                                                                                                                       | 20/820 [08:07<5:25:09, 24.39s/it]


  3%|██▉                                                                                                          | 22/820 [08:57<5:28:32, 24.70s/it]

  3%|███                                                                                                          | 23/820 [09:21<5:25:31, 24.51s/it]

  3%|██▊                                                                                            | 24/820 [09:45<5:24:26, 24.45s/it]

  3%|██▉                                                                                            | 25/820 [10:09<5:22:25, 24.33s/it]

  3%|███                                                                                            | 26/820 [10:33<5:20:43, 24.24s/it]

  3%|███▏                                                                                           | 27/820 [10:58<5:21:01, 24.29s/it]

  3%|███▏                                                                                           | 28/820 [11:21<5:17:28, 24.05s/it]

  4%|███▎                                                                                           | 29/820 [11:46<5:19:29, 24.23s/it]

  4%|███▍                                                                                           | 30/820 [12:10<5:16:17, 24.02s/it]

  4%|███▌                                                                                           | 31/820 [12:34<5:17:11, 24.12s/it]

  4%|███▋                                                                                           | 32/820 [12:59<5:19:02, 24.29s/it]
{'loss': 2.2827, 'learning_rate': 9.980168004686238e-05, 'epoch': 0.39}

  4%|███▊                                                                                           | 33/820 [13:23<5:19:23, 24.35s/it]

  4%|███▉                                                                                           | 34/820 [13:47<5:17:23, 24.23s/it]


  4%|████▏                                                                                          | 36/820 [14:36<5:17:57, 24.33s/it]

  5%|████▎                                                                                          | 37/820 [15:00<5:18:40, 24.42s/it]
{'loss': 2.2515, 'learning_rate': 9.970617530466526e-05, 'epoch': 0.45}


  5%|████▌                                                                                          | 39/820 [15:50<5:20:21, 24.61s/it]

  5%|████▋                                                                                          | 40/820 [16:15<5:20:54, 24.69s/it]
{'loss': 2.3011, 'learning_rate': 9.963991960698442e-05, 'epoch': 0.49}

  5%|████▊                                                                                          | 41/820 [16:40<5:20:13, 24.66s/it]

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:57<00:03,  3.55s/it]

{'eval_loss': 2.3294382095336914, 'eval_runtime': 122.0246, 'eval_samples_per_second': 4.515, 'eval_steps_per_second': 0.287, 'epoch': 0.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  5%|████▊                                                                                         | 42/820 [19:07<13:15:42, 61.37s/it]

  5%|████▉                                                                                         | 43/820 [19:31<10:49:29, 50.15s/it]

  5%|█████                                                                                          | 44/820 [19:55<9:07:20, 42.32s/it]

  5%|█████▏                                                                                         | 45/820 [20:18<7:53:17, 36.64s/it]

  6%|█████▎                                                                                         | 46/820 [20:42<7:04:11, 32.88s/it]

  6%|█████▍                                                                                         | 47/820 [21:06<6:28:57, 30.19s/it]

  6%|█████▌                                                                                         | 48/820 [21:31<6:06:36, 28.49s/it]

  6%|█████▋                                                                                         | 49/820 [21:55<5:51:14, 27.33s/it]

  6%|█████▊                                                                                         | 50/820 [22:18<5:35:04, 26.11s/it]

  6%|█████▉                                                                                         | 51/820 [22:42<5:26:26, 25.47s/it]

  6%|██████                                                                                         | 52/820 [23:06<5:19:58, 25.00s/it]

  6%|██████▏                                                                                        | 53/820 [23:31<5:16:54, 24.79s/it]

  7%|██████▎                                                                                        | 54/820 [23:54<5:11:32, 24.40s/it]

  7%|██████▎                                                                                        | 55/820 [24:18<5:09:53, 24.31s/it]

  7%|██████▍                                                                                        | 56/820 [24:43<5:10:26, 24.38s/it]

  7%|██████▌                                                                                        | 57/820 [25:07<5:09:44, 24.36s/it]

  7%|██████▋                                                                                        | 58/820 [25:31<5:09:12, 24.35s/it]
{'loss': 2.3175, 'learning_rate': 9.910198025229868e-05, 'epoch': 0.71}


  7%|██████▉                                                                                        | 60/820 [26:21<5:10:29, 24.51s/it]

  7%|███████                                                                                        | 61/820 [26:45<5:09:11, 24.44s/it]

  8%|███████▏                                                                                       | 62/820 [27:09<5:08:15, 24.40s/it]

  8%|███████▎                                                                                       | 63/820 [27:33<5:06:35, 24.30s/it]

  8%|███████▍                                                                                       | 64/820 [27:58<5:06:16, 24.31s/it]

  8%|███████▌                                                                                       | 65/820 [28:22<5:04:48, 24.22s/it]

  8%|███████▋                                                                                       | 66/820 [28:46<5:03:15, 24.13s/it]

  8%|███████▊                                                                                       | 67/820 [29:10<5:02:37, 24.11s/it]

  8%|███████▉                                                                                       | 68/820 [29:34<5:01:24, 24.05s/it]

  8%|███████▉                                                                                       | 69/820 [29:58<5:01:41, 24.10s/it]
{'loss': 2.2462, 'learning_rate': 9.87861009161778e-05, 'epoch': 0.84}


  9%|████████▏                                                                                      | 71/820 [30:45<4:56:04, 23.72s/it]

  9%|████████▎                                                                                      | 72/820 [31:09<4:56:28, 23.78s/it]

  9%|████████▍                                                                                      | 73/820 [31:33<4:58:58, 24.01s/it]

  9%|████████▌                                                                                      | 74/820 [31:57<4:58:20, 23.99s/it]

  9%|████████▋                                                                                      | 75/820 [32:21<4:58:14, 24.02s/it]

  9%|████████▊                                                                                      | 76/820 [32:46<4:59:09, 24.13s/it]
{'loss': 2.5231, 'learning_rate': 9.856486474351502e-05, 'epoch': 0.93}


 10%|█████████                                                                                      | 78/820 [33:35<5:02:05, 24.43s/it]

 10%|█████████▏                                                                                     | 79/820 [33:59<4:59:51, 24.28s/it]

 10%|█████████▎                                                                                     | 80/820 [34:23<4:58:22, 24.19s/it]

 10%|█████████▍                                                                                     | 81/820 [34:47<4:57:52, 24.18s/it]

 10%|█████████▌                                                                                     | 82/820 [35:00<4:13:59, 20.65s/it]
{'loss': 2.3824, 'learning_rate': 9.827534103147814e-05, 'epoch': 1.0}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:59<00:03,  3.63s/it]
{'eval_loss': 2.3736977577209473, 'eval_runtime': 124.358, 'eval_samples_per_second': 4.431, 'eval_steps_per_second': 0.281, 'epoch': 1.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 10%|█████████▌                                                                                    | 83/820 [37:29<12:09:15, 59.37s/it]

 10%|█████████▋                                                                                     | 84/820 [37:54<9:59:11, 48.85s/it]

 10%|█████████▊                                                                                     | 85/820 [38:18<8:27:05, 41.39s/it]

 10%|█████████▉                                                                                     | 86/820 [38:42<7:24:00, 36.30s/it]

 11%|██████████                                                                                     | 87/820 [39:06<6:38:41, 32.63s/it]

 11%|██████████▏                                                                                    | 88/820 [39:30<6:07:28, 30.12s/it]

 11%|██████████▎                                                                                    | 89/820 [39:54<5:42:49, 28.14s/it]

 11%|██████████▍                                                                                    | 90/820 [40:19<5:31:56, 27.28s/it]

 11%|██████████▌                                                                                    | 91/820 [40:43<5:19:58, 26.33s/it]

 11%|██████████▋                                                                                    | 92/820 [41:07<5:11:11, 25.65s/it]

 11%|██████████▊                                                                                    | 93/820 [41:32<5:06:40, 25.31s/it]

 11%|██████████▉                                                                                    | 94/820 [41:56<5:03:38, 25.09s/it]
{'loss': 2.0654, 'learning_rate': 9.761823152081608e-05, 'epoch': 1.15}


 12%|███████████                                                                                    | 96/820 [42:46<4:59:36, 24.83s/it]

 12%|███████████▏                                                                                   | 97/820 [43:10<4:58:17, 24.75s/it]

 12%|███████████▎                                                                                   | 98/820 [43:35<4:56:54, 24.67s/it]

 12%|███████████▍                                                                                   | 99/820 [43:59<4:54:21, 24.50s/it]

 12%|███████████▍                                                                                  | 100/820 [44:22<4:49:05, 24.09s/it]

 12%|███████████▌                                                                                  | 101/820 [44:46<4:48:22, 24.06s/it]
{'loss': 2.1434, 'learning_rate': 9.71873084635873e-05, 'epoch': 1.23}


 13%|███████████▊                                                                                  | 103/820 [45:33<4:45:01, 23.85s/it]

 13%|███████████▉                                                                                  | 104/820 [45:58<4:47:32, 24.10s/it]

 13%|████████████                                                                                  | 105/820 [46:21<4:44:30, 23.87s/it]

 13%|████████████▏                                                                                 | 106/820 [46:45<4:46:11, 24.05s/it]

 13%|████████████▎                                                                                 | 107/820 [47:10<4:47:12, 24.17s/it]

 13%|████████████▍                                                                                 | 108/820 [47:34<4:48:18, 24.30s/it]

 13%|████████████▍                                                                                 | 109/820 [47:59<4:47:35, 24.27s/it]

 13%|████████████▌                                                                                 | 110/820 [48:23<4:46:56, 24.25s/it]
{'loss': 2.0999, 'learning_rate': 9.65823330632631e-05, 'epoch': 1.34}


 14%|████████████▊                                                                                 | 112/820 [49:12<4:47:47, 24.39s/it]

 14%|████████████▉                                                                                 | 113/820 [49:37<4:48:06, 24.45s/it]

 14%|█████████████                                                                                 | 114/820 [50:01<4:47:35, 24.44s/it]
{'loss': 1.932, 'learning_rate': 9.629523664549085e-05, 'epoch': 1.39}


 14%|█████████████▎                                                                                | 116/820 [50:48<4:43:22, 24.15s/it]
{'loss': 1.9897, 'learning_rate': 9.614751593589347e-05, 'epoch': 1.41}

 14%|█████████████▍                                                                                | 117/820 [51:12<4:40:04, 23.90s/it]


 15%|█████████████▋                                                                                | 119/820 [51:59<4:36:59, 23.71s/it]
{'loss': 2.161, 'learning_rate': 9.59207441241603e-05, 'epoch': 1.45}


 15%|█████████████▊                                                                                | 121/820 [52:48<4:41:38, 24.18s/it]

 15%|█████████████▉                                                                                | 122/820 [53:10<4:34:43, 23.62s/it]

 15%|██████████████                                                                                | 123/820 [53:34<4:35:51, 23.75s/it]
{'loss': 2.0772, 'learning_rate': 9.560874017089259e-05, 'epoch': 1.5}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:59<00:03,  3.56s/it]
{'eval_loss': 2.0904338359832764, 'eval_runtime': 124.157, 'eval_samples_per_second': 4.438, 'eval_steps_per_second': 0.282, 'epoch': 1.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 2.0591, 'learning_rate': 9.552902524811649e-05, 'epoch': 1.51}

 15%|██████████████▎                                                                               | 125/820 [56:27<9:39:47, 50.05s/it]

 15%|██████████████▍                                                                               | 126/820 [56:52<8:09:37, 42.33s/it]

 15%|██████████████▌                                                                               | 127/820 [57:17<7:09:07, 37.15s/it]

 16%|██████████████▋                                                                               | 128/820 [57:41<6:25:00, 33.38s/it]

 16%|██████████████▊                                                                               | 129/820 [58:06<5:53:38, 30.71s/it]
{'loss': 2.1226, 'learning_rate': 9.512022696376535e-05, 'epoch': 1.57}


 16%|███████████████                                                                               | 131/820 [58:55<5:15:19, 27.46s/it]

 16%|███████████████▏                                                                              | 132/820 [59:18<5:01:03, 26.25s/it]
{'loss': 2.0086, 'learning_rate': 9.486681340737334e-05, 'epoch': 1.61}

 16%|███████████████▏                                                                              | 133/820 [59:42<4:54:04, 25.68s/it]


 16%|███████████████▏                                                                            | 135/820 [1:00:31<4:44:22, 24.91s/it]

 17%|███████████████▎                                                                            | 136/820 [1:00:55<4:40:47, 24.63s/it]

 17%|███████████████▎                                                                            | 137/820 [1:01:19<4:40:03, 24.60s/it]

 17%|███████████████▍                                                                            | 138/820 [1:01:44<4:39:15, 24.57s/it]

 17%|███████████████▌                                                                            | 139/820 [1:02:08<4:37:24, 24.44s/it]

 17%|███████████████▋                                                                            | 140/820 [1:02:32<4:36:31, 24.40s/it]

 17%|███████████████▊                                                                            | 141/820 [1:02:55<4:32:42, 24.10s/it]

 17%|███████████████▉                                                                            | 142/820 [1:03:18<4:27:41, 23.69s/it]

 17%|████████████████                                                                            | 143/820 [1:03:43<4:30:05, 23.94s/it]
{'loss': 2.0424, 'learning_rate': 9.388605894439551e-05, 'epoch': 1.74}


 18%|████████████████▎                                                                           | 145/820 [1:04:30<4:26:57, 23.73s/it]

 18%|████████████████▍                                                                           | 146/820 [1:04:54<4:28:23, 23.89s/it]

 18%|████████████████▍                                                                           | 147/820 [1:05:18<4:29:18, 24.01s/it]
{'loss': 2.0985, 'learning_rate': 9.350956946650135e-05, 'epoch': 1.79}


 18%|████████████████▋                                                                           | 149/820 [1:06:07<4:29:45, 24.12s/it]

 18%|████████████████▊                                                                           | 150/820 [1:06:31<4:29:34, 24.14s/it]

 18%|████████████████▉                                                                           | 151/820 [1:06:54<4:26:43, 23.92s/it]
{'loss': 2.091, 'learning_rate': 9.312263389011571e-05, 'epoch': 1.84}


 19%|█████████████████▏                                                                          | 153/820 [1:07:43<4:29:00, 24.20s/it]

 19%|█████████████████▎                                                                          | 154/820 [1:08:07<4:27:30, 24.10s/it]

 19%|█████████████████▍                                                                          | 155/820 [1:08:32<4:28:19, 24.21s/it]

 19%|█████████████████▌                                                                          | 156/820 [1:08:56<4:28:20, 24.25s/it]

 19%|█████████████████▌                                                                          | 157/820 [1:09:20<4:27:49, 24.24s/it]

 19%|█████████████████▋                                                                          | 158/820 [1:09:44<4:27:14, 24.22s/it]
{'loss': 1.9206, 'learning_rate': 9.242064153023325e-05, 'epoch': 1.93}

 19%|█████████████████▊                                                                          | 159/820 [1:10:09<4:27:20, 24.27s/it]


 20%|██████████████████                                                                          | 161/820 [1:10:57<4:27:11, 24.33s/it]

 20%|██████████████████▏                                                                         | 162/820 [1:11:22<4:26:58, 24.34s/it]

 20%|██████████████████▎                                                                         | 163/820 [1:11:46<4:24:43, 24.18s/it]

 20%|██████████████████▍                                                                         | 164/820 [1:11:57<3:43:15, 20.42s/it]
{'loss': 1.9062, 'learning_rate': 9.179408952227164e-05, 'epoch': 2.0}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:56<00:03,  3.53s/it]
{'eval_loss': 2.084754228591919, 'eval_runtime': 121.2125, 'eval_samples_per_second': 4.546, 'eval_steps_per_second': 0.289, 'epoch': 2.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 20%|██████████████████▎                                                                        | 165/820 [1:14:24<10:35:21, 58.20s/it]

 20%|██████████████████▌                                                                         | 166/820 [1:14:48<8:42:15, 47.91s/it]

 20%|██████████████████▋                                                                         | 167/820 [1:15:12<7:23:09, 40.72s/it]

 20%|██████████████████▊                                                                         | 168/820 [1:15:35<6:27:42, 35.68s/it]

 21%|██████████████████▉                                                                         | 169/820 [1:16:00<5:50:44, 32.33s/it]

 21%|███████████████████                                                                         | 170/820 [1:16:24<5:22:49, 29.80s/it]

 21%|███████████████████▏                                                                        | 171/820 [1:16:48<5:04:20, 28.14s/it]

 21%|███████████████████▎                                                                        | 172/820 [1:17:12<4:50:19, 26.88s/it]

 21%|███████████████████▍                                                                        | 173/820 [1:17:36<4:40:04, 25.97s/it]

 21%|███████████████████▌                                                                        | 174/820 [1:18:00<4:34:12, 25.47s/it]

 21%|███████████████████▋                                                                        | 175/820 [1:18:25<4:30:28, 25.16s/it]

 21%|███████████████████▋                                                                        | 176/820 [1:18:49<4:27:37, 24.93s/it]

 22%|███████████████████▊                                                                        | 177/820 [1:19:13<4:25:40, 24.79s/it]

 22%|███████████████████▉                                                                        | 178/820 [1:19:37<4:20:41, 24.36s/it]

 22%|████████████████████                                                                        | 179/820 [1:20:00<4:17:04, 24.06s/it]

 22%|████████████████████▏                                                                       | 180/820 [1:20:24<4:15:31, 23.95s/it]

 22%|████████████████████▎                                                                       | 181/820 [1:20:48<4:16:13, 24.06s/it]

 22%|████████████████████▍                                                                       | 182/820 [1:21:12<4:16:21, 24.11s/it]

 22%|████████████████████▌                                                                       | 183/820 [1:21:37<4:16:18, 24.14s/it]

 22%|████████████████████▋                                                                       | 184/820 [1:22:01<4:17:09, 24.26s/it]

 23%|████████████████████▊                                                                       | 185/820 [1:22:25<4:16:36, 24.25s/it]

 23%|████████████████████▊                                                                       | 186/820 [1:22:49<4:13:10, 23.96s/it]

 23%|████████████████████▉                                                                       | 187/820 [1:23:13<4:12:16, 23.91s/it]

 23%|█████████████████████                                                                       | 188/820 [1:23:37<4:13:46, 24.09s/it]

 23%|█████████████████████▏                                                                      | 189/820 [1:24:01<4:13:48, 24.13s/it]

 23%|█████████████████████▎                                                                      | 190/820 [1:24:26<4:14:18, 24.22s/it]
{'loss': 2.0364, 'learning_rate': 8.882273895681352e-05, 'epoch': 2.32}


 23%|█████████████████████▌                                                                      | 192/820 [1:25:13<4:10:20, 23.92s/it]

 24%|█████████████████████▋                                                                      | 193/820 [1:25:38<4:11:36, 24.08s/it]

 24%|█████████████████████▊                                                                      | 194/820 [1:26:02<4:11:56, 24.15s/it]

 24%|█████████████████████▉                                                                      | 195/820 [1:26:26<4:11:43, 24.17s/it]

 24%|█████████████████████▉                                                                      | 196/820 [1:26:50<4:11:35, 24.19s/it]

 24%|██████████████████████                                                                      | 197/820 [1:27:15<4:11:18, 24.20s/it]

 24%|██████████████████████▏                                                                     | 198/820 [1:27:38<4:09:57, 24.11s/it]

 24%|██████████████████████▎                                                                     | 199/820 [1:28:02<4:08:43, 24.03s/it]

 24%|██████████████████████▍                                                                     | 200/820 [1:28:27<4:09:45, 24.17s/it]

 25%|██████████████████████▌                                                                     | 201/820 [1:28:51<4:09:51, 24.22s/it]

 25%|██████████████████████▋                                                                     | 202/820 [1:29:15<4:08:04, 24.09s/it]

 25%|██████████████████████▊                                                                     | 203/820 [1:29:39<4:06:53, 24.01s/it]

 25%|██████████████████████▉                                                                     | 204/820 [1:30:02<4:04:01, 23.77s/it]

 25%|███████████████████████                                                                     | 205/820 [1:30:26<4:03:35, 23.76s/it]
{'loss': 1.9876, 'learning_rate': 8.692741034935053e-05, 'epoch': 2.5}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:56<00:03,  3.53s/it]
{'eval_loss': 2.085693359375, 'eval_runtime': 121.2725, 'eval_samples_per_second': 4.543, 'eval_steps_per_second': 0.289, 'epoch': 2.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 25%|██████████████████████▊                                                                    | 206/820 [1:32:52<10:19:28, 60.53s/it]

 25%|███████████████████████▏                                                                    | 207/820 [1:33:16<8:27:06, 49.64s/it]

 25%|███████████████████████▎                                                                    | 208/820 [1:33:41<7:09:12, 42.08s/it]

 25%|███████████████████████▍                                                                    | 209/820 [1:34:05<6:14:07, 36.74s/it]

 26%|███████████████████████▌                                                                    | 210/820 [1:34:29<5:35:36, 33.01s/it]

 26%|███████████████████████▋                                                                    | 211/820 [1:34:54<5:08:33, 30.40s/it]

 26%|███████████████████████▊                                                                    | 212/820 [1:35:18<4:49:28, 28.57s/it]

 26%|███████████████████████▉                                                                    | 213/820 [1:35:42<4:35:58, 27.28s/it]

 26%|████████████████████████                                                                    | 214/820 [1:36:06<4:26:29, 26.39s/it]

 26%|████████████████████████                                                                    | 215/820 [1:36:30<4:18:17, 25.61s/it]

 26%|████████████████████████▏                                                                   | 216/820 [1:36:55<4:14:37, 25.29s/it]

 26%|████████████████████████▎                                                                   | 217/820 [1:37:19<4:10:11, 24.89s/it]

 27%|████████████████████████▍                                                                   | 218/820 [1:37:43<4:08:41, 24.79s/it]

 27%|████████████████████████▌                                                                   | 219/820 [1:38:08<4:06:47, 24.64s/it]

 27%|████████████████████████▋                                                                   | 220/820 [1:38:32<4:06:02, 24.60s/it]

 27%|████████████████████████▊                                                                   | 221/820 [1:38:57<4:05:23, 24.58s/it]

 27%|████████████████████████▉                                                                   | 222/820 [1:39:20<4:01:10, 24.20s/it]

 27%|█████████████████████████                                                                   | 223/820 [1:39:44<4:00:50, 24.21s/it]

 27%|█████████████████████████▏                                                                  | 224/820 [1:40:09<4:01:18, 24.29s/it]

 27%|█████████████████████████▏                                                                  | 225/820 [1:40:33<4:00:27, 24.25s/it]

 28%|█████████████████████████▎                                                                  | 226/820 [1:40:57<4:00:02, 24.25s/it]

 28%|█████████████████████████▍                                                                  | 227/820 [1:41:20<3:56:22, 23.92s/it]

 28%|█████████████████████████▌                                                                  | 228/820 [1:41:45<3:57:46, 24.10s/it]

 28%|█████████████████████████▋                                                                  | 229/820 [1:42:09<3:56:56, 24.05s/it]

 28%|█████████████████████████▊                                                                  | 230/820 [1:42:33<3:57:17, 24.13s/it]

 28%|█████████████████████████▉                                                                  | 231/820 [1:42:57<3:57:41, 24.21s/it]

 28%|██████████████████████████                                                                  | 232/820 [1:43:22<3:58:15, 24.31s/it]
{'loss': 2.0798, 'learning_rate': 8.32062871990396e-05, 'epoch': 2.83}


 29%|██████████████████████████▎                                                                 | 234/820 [1:44:10<3:55:45, 24.14s/it]

 29%|██████████████████████████▎                                                                 | 235/820 [1:44:34<3:54:36, 24.06s/it]

 29%|██████████████████████████▍                                                                 | 236/820 [1:44:57<3:53:25, 23.98s/it]

 29%|██████████████████████████▌                                                                 | 237/820 [1:45:22<3:53:51, 24.07s/it]

 29%|██████████████████████████▋                                                                 | 238/820 [1:45:46<3:53:54, 24.11s/it]

 29%|██████████████████████████▊                                                                 | 239/820 [1:46:10<3:52:57, 24.06s/it]

 29%|██████████████████████████▉                                                                 | 240/820 [1:46:34<3:52:02, 24.00s/it]

 29%|███████████████████████████                                                                 | 241/820 [1:46:58<3:53:21, 24.18s/it]

 30%|███████████████████████████▏                                                                | 242/820 [1:47:23<3:53:17, 24.22s/it]

 30%|███████████████████████████▎                                                                | 243/820 [1:47:46<3:51:57, 24.12s/it]

 30%|███████████████████████████▍                                                                | 244/820 [1:48:10<3:49:06, 23.86s/it]

 30%|███████████████████████████▍                                                                | 245/820 [1:48:34<3:49:58, 24.00s/it]

 30%|███████████████████████████▌                                                                | 246/820 [1:48:46<3:15:59, 20.49s/it]
{'loss': 2.2192, 'learning_rate': 8.113120526833768e-05, 'epoch': 3.0}

































 94%|████████████████████████████████████████████████████████████████████████████████████████████▍     | 33/35 [01:52<00:07,  3.53s/it]
{'eval_loss': 2.0846152305603027, 'eval_runtime': 120.9521, 'eval_samples_per_second': 4.556, 'eval_steps_per_second': 0.289, 'epoch': 3.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 30%|███████████████████████████▋                                                                | 247/820 [1:51:12<9:13:29, 57.96s/it]

 30%|███████████████████████████▊                                                                | 248/820 [1:51:36<7:36:42, 47.91s/it]

 30%|███████████████████████████▉                                                                | 249/820 [1:52:00<6:28:34, 40.83s/it]

 30%|████████████████████████████                                                                | 250/820 [1:52:24<5:39:31, 35.74s/it]

 31%|████████████████████████████▏                                                               | 251/820 [1:52:49<5:06:43, 32.34s/it]

 31%|████████████████████████████▎                                                               | 252/820 [1:53:13<4:43:47, 29.98s/it]

 31%|████████████████████████████▍                                                               | 253/820 [1:53:38<4:27:52, 28.35s/it]

 31%|████████████████████████████▍                                                               | 254/820 [1:54:02<4:14:42, 27.00s/it]

 31%|████████████████████████████▌                                                               | 255/820 [1:54:26<4:07:08, 26.24s/it]

 31%|████████████████████████████▋                                                               | 256/820 [1:54:50<4:00:52, 25.63s/it]

 31%|████████████████████████████▊                                                               | 257/820 [1:55:15<3:56:38, 25.22s/it]

 31%|████████████████████████████▉                                                               | 258/820 [1:55:39<3:54:22, 25.02s/it]

 32%|█████████████████████████████                                                               | 259/820 [1:56:03<3:50:40, 24.67s/it]

 32%|█████████████████████████████▏                                                              | 260/820 [1:56:27<3:49:04, 24.54s/it]

 32%|█████████████████████████████▎                                                              | 261/820 [1:56:51<3:47:47, 24.45s/it]

 32%|█████████████████████████████▍                                                              | 262/820 [1:57:16<3:47:06, 24.42s/it]

 32%|█████████████████████████████▌                                                              | 263/820 [1:57:40<3:45:11, 24.26s/it]

 32%|█████████████████████████████▌                                                              | 264/820 [1:58:04<3:43:40, 24.14s/it]

 32%|█████████████████████████████▋                                                              | 265/820 [1:58:28<3:43:22, 24.15s/it]

 32%|█████████████████████████████▊                                                              | 266/820 [1:58:52<3:44:18, 24.29s/it]

 33%|█████████████████████████████▉                                                              | 267/820 [1:59:16<3:42:41, 24.16s/it]
{'loss': 2.0578, 'learning_rate': 7.784892861338386e-05, 'epoch': 3.26}


 33%|██████████████████████████████▏                                                             | 269/820 [2:00:05<3:42:46, 24.26s/it]
{'loss': 1.9439, 'learning_rate': 7.752637260816045e-05, 'epoch': 3.28}

 33%|██████████████████████████████▎                                                             | 270/820 [2:00:29<3:41:06, 24.12s/it]


 33%|██████████████████████████████▌                                                             | 272/820 [2:01:17<3:40:08, 24.10s/it]

 33%|██████████████████████████████▋                                                             | 273/820 [2:01:41<3:40:55, 24.23s/it]

 33%|██████████████████████████████▋                                                             | 274/820 [2:02:06<3:40:29, 24.23s/it]

 34%|██████████████████████████████▊                                                             | 275/820 [2:02:30<3:40:16, 24.25s/it]

 34%|██████████████████████████████▉                                                             | 276/820 [2:02:54<3:40:24, 24.31s/it]
{'loss': 1.9544, 'learning_rate': 7.638454339455919e-05, 'epoch': 3.37}


 34%|███████████████████████████████▏                                                            | 278/820 [2:03:43<3:40:00, 24.36s/it]

 34%|███████████████████████████████▎                                                            | 279/820 [2:04:07<3:39:31, 24.35s/it]

 34%|███████████████████████████████▍                                                            | 280/820 [2:04:32<3:39:33, 24.40s/it]

 34%|███████████████████████████████▌                                                            | 281/820 [2:04:56<3:39:14, 24.41s/it]
{'loss': 1.9834, 'learning_rate': 7.555702469998614e-05, 'epoch': 3.43}


 35%|███████████████████████████████▊                                                            | 283/820 [2:05:45<3:38:14, 24.38s/it]

 35%|███████████████████████████████▊                                                            | 284/820 [2:06:08<3:32:58, 23.84s/it]

 35%|███████████████████████████████▉                                                            | 285/820 [2:06:32<3:32:48, 23.87s/it]

 35%|████████████████████████████████                                                            | 286/820 [2:06:56<3:33:30, 23.99s/it]

 35%|████████████████████████████████▏                                                           | 287/820 [2:07:20<3:34:25, 24.14s/it]
{'loss': 2.0087, 'learning_rate': 7.455137464810399e-05, 'epoch': 3.5}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:56<00:03,  3.53s/it]
{'eval_loss': 2.0897228717803955, 'eval_runtime': 121.3433, 'eval_samples_per_second': 4.541, 'eval_steps_per_second': 0.288, 'epoch': 3.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 35%|████████████████████████████████▎                                                           | 288/820 [2:09:47<8:59:01, 60.79s/it]

 35%|████████████████████████████████▍                                                           | 289/820 [2:10:10<7:19:37, 49.67s/it]

 35%|████████████████████████████████▌                                                           | 290/820 [2:10:35<6:11:18, 42.03s/it]

 35%|████████████████████████████████▋                                                           | 291/820 [2:10:59<5:24:08, 36.76s/it]

 36%|████████████████████████████████▊                                                           | 292/820 [2:11:23<4:49:42, 32.92s/it]

 36%|████████████████████████████████▊                                                           | 293/820 [2:11:48<4:26:55, 30.39s/it]

 36%|████████████████████████████████▉                                                           | 294/820 [2:12:11<4:08:56, 28.40s/it]

 36%|█████████████████████████████████                                                           | 295/820 [2:12:36<3:57:59, 27.20s/it]

 36%|█████████████████████████████████▏                                                          | 296/820 [2:13:00<3:49:01, 26.22s/it]

 36%|█████████████████████████████████▎                                                          | 297/820 [2:13:24<3:43:38, 25.66s/it]

 36%|█████████████████████████████████▍                                                          | 298/820 [2:13:48<3:39:36, 25.24s/it]

 36%|█████████████████████████████████▌                                                          | 299/820 [2:14:13<3:37:14, 25.02s/it]

 37%|█████████████████████████████████▋                                                          | 300/820 [2:14:37<3:34:38, 24.77s/it]

 37%|█████████████████████████████████▊                                                          | 301/820 [2:15:01<3:31:47, 24.48s/it]

 37%|█████████████████████████████████▉                                                          | 302/820 [2:15:25<3:31:24, 24.49s/it]
{'loss': 1.9511, 'learning_rate': 7.198043311346199e-05, 'epoch': 3.68}


 37%|██████████████████████████████████                                                          | 304/820 [2:16:14<3:30:02, 24.42s/it]

 37%|██████████████████████████████████▏                                                         | 305/820 [2:16:38<3:28:25, 24.28s/it]

 37%|██████████████████████████████████▎                                                         | 306/820 [2:17:02<3:26:43, 24.13s/it]

 37%|██████████████████████████████████▍                                                         | 307/820 [2:17:26<3:27:05, 24.22s/it]

 38%|██████████████████████████████████▌                                                         | 308/820 [2:17:51<3:27:29, 24.31s/it]

 38%|██████████████████████████████████▋                                                         | 309/820 [2:18:15<3:26:11, 24.21s/it]

 38%|██████████████████████████████████▊                                                         | 310/820 [2:18:39<3:25:56, 24.23s/it]

 38%|██████████████████████████████████▉                                                         | 311/820 [2:19:03<3:25:39, 24.24s/it]

 38%|███████████████████████████████████                                                         | 312/820 [2:19:28<3:25:51, 24.31s/it]

 38%|███████████████████████████████████                                                         | 313/820 [2:19:52<3:25:42, 24.34s/it]

 38%|███████████████████████████████████▏                                                        | 314/820 [2:20:17<3:25:24, 24.36s/it]

 38%|███████████████████████████████████▎                                                        | 315/820 [2:20:41<3:24:42, 24.32s/it]

 39%|███████████████████████████████████▍                                                        | 316/820 [2:21:05<3:24:01, 24.29s/it]

 39%|███████████████████████████████████▌                                                        | 317/820 [2:21:29<3:23:37, 24.29s/it]

 39%|███████████████████████████████████▋                                                        | 318/820 [2:21:53<3:22:01, 24.15s/it]

 39%|███████████████████████████████████▊                                                        | 319/820 [2:22:17<3:21:58, 24.19s/it]
{'loss': 1.8944, 'learning_rate': 6.8977487003466e-05, 'epoch': 3.89}

 39%|███████████████████████████████████▉                                                        | 320/820 [2:22:42<3:22:30, 24.30s/it]


 39%|████████████████████████████████████▏                                                       | 322/820 [2:23:30<3:20:44, 24.19s/it]

 39%|████████████████████████████████████▏                                                       | 323/820 [2:23:54<3:20:29, 24.21s/it]

 40%|████████████████████████████████████▎                                                       | 324/820 [2:24:18<3:19:08, 24.09s/it]

 40%|████████████████████████████████████▍                                                       | 325/820 [2:24:42<3:19:10, 24.14s/it]

 40%|████████████████████████████████████▌                                                       | 326/820 [2:25:07<3:19:02, 24.17s/it]

 40%|████████████████████████████████████▋                                                       | 327/820 [2:25:31<3:19:22, 24.27s/it]

 40%|████████████████████████████████████▊                                                       | 328/820 [2:25:43<2:47:54, 20.48s/it]
{'loss': 2.1682, 'learning_rate': 6.735354404902585e-05, 'epoch': 4.0}

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:56<00:03,  3.53s/it]

{'eval_loss': 2.0867912769317627, 'eval_runtime': 121.1648, 'eval_samples_per_second': 4.548, 'eval_steps_per_second': 0.289, 'epoch': 4.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 2.0113, 'learning_rate': 6.717176770508119e-05, 'epoch': 4.01}
 40%|████████████████████████████████████▉                                                       | 329/820 [2:28:09<7:56:01, 58.17s/it]

 40%|█████████████████████████████████████                                                       | 330/820 [2:28:33<6:31:58, 48.00s/it]

 40%|█████████████████████████████████████▏                                                      | 331/820 [2:28:56<5:30:38, 40.57s/it]

 40%|█████████████████████████████████████▏                                                      | 332/820 [2:29:20<4:49:09, 35.55s/it]

 41%|█████████████████████████████████████▎                                                      | 333/820 [2:29:44<4:19:51, 32.02s/it]

 41%|█████████████████████████████████████▍                                                      | 334/820 [2:30:08<4:00:33, 29.70s/it]

 41%|█████████████████████████████████████▌                                                      | 335/820 [2:30:32<3:45:37, 27.91s/it]

 41%|█████████████████████████████████████▋                                                      | 336/820 [2:30:56<3:36:39, 26.86s/it]

 41%|█████████████████████████████████████▊                                                      | 337/820 [2:31:21<3:30:29, 26.15s/it]

 41%|█████████████████████████████████████▉                                                      | 338/820 [2:31:45<3:26:02, 25.65s/it]

 41%|██████████████████████████████████████                                                      | 339/820 [2:32:09<3:21:20, 25.11s/it]

 41%|██████████████████████████████████████▏                                                     | 340/820 [2:32:34<3:18:59, 24.87s/it]

 42%|██████████████████████████████████████▎                                                     | 341/820 [2:32:58<3:17:42, 24.77s/it]

 42%|██████████████████████████████████████▎                                                     | 342/820 [2:33:21<3:13:25, 24.28s/it]

 42%|██████████████████████████████████████▍                                                     | 343/820 [2:33:45<3:12:14, 24.18s/it]

 42%|██████████████████████████████████████▌                                                     | 344/820 [2:34:10<3:12:37, 24.28s/it]

 42%|██████████████████████████████████████▋                                                     | 345/820 [2:34:34<3:12:02, 24.26s/it]

 42%|██████████████████████████████████████▊                                                     | 346/820 [2:34:59<3:12:25, 24.36s/it]

 42%|██████████████████████████████████████▉                                                     | 347/820 [2:35:23<3:11:54, 24.34s/it]

 42%|███████████████████████████████████████                                                     | 348/820 [2:35:46<3:08:50, 24.00s/it]

 43%|███████████████████████████████████████▏                                                    | 349/820 [2:36:10<3:09:13, 24.10s/it]

 43%|███████████████████████████████████████▎                                                    | 350/820 [2:36:35<3:09:19, 24.17s/it]

 43%|███████████████████████████████████████▍                                                    | 351/820 [2:36:59<3:09:03, 24.19s/it]

 43%|███████████████████████████████████████▍                                                    | 352/820 [2:37:23<3:08:27, 24.16s/it]

 43%|███████████████████████████████████████▌                                                    | 353/820 [2:37:48<3:09:25, 24.34s/it]

 43%|███████████████████████████████████████▋                                                    | 354/820 [2:38:12<3:08:56, 24.33s/it]

 43%|███████████████████████████████████████▊                                                    | 355/820 [2:38:36<3:07:26, 24.19s/it]

 43%|███████████████████████████████████████▉                                                    | 356/820 [2:39:00<3:07:48, 24.28s/it]

 44%|████████████████████████████████████████                                                    | 357/820 [2:39:25<3:07:25, 24.29s/it]

 44%|████████████████████████████████████████▏                                                   | 358/820 [2:39:49<3:07:21, 24.33s/it]

 44%|████████████████████████████████████████▎                                                   | 359/820 [2:40:14<3:07:01, 24.34s/it]

 44%|████████████████████████████████████████▍                                                   | 360/820 [2:40:38<3:07:00, 24.39s/it]

 44%|████████████████████████████████████████▌                                                   | 361/820 [2:41:02<3:05:25, 24.24s/it]

 44%|████████████████████████████████████████▌                                                   | 362/820 [2:41:25<3:02:35, 23.92s/it]

 44%|████████████████████████████████████████▋                                                   | 363/820 [2:41:49<3:03:01, 24.03s/it]

 44%|████████████████████████████████████████▊                                                   | 364/820 [2:42:14<3:03:59, 24.21s/it]

 45%|████████████████████████████████████████▉                                                   | 365/820 [2:42:38<3:02:47, 24.10s/it]

 45%|█████████████████████████████████████████                                                   | 366/820 [2:43:02<3:02:48, 24.16s/it]

 45%|█████████████████████████████████████████▏                                                  | 367/820 [2:43:26<3:02:34, 24.18s/it]

 45%|█████████████████████████████████████████▎                                                  | 368/820 [2:43:50<3:00:19, 23.94s/it]

 45%|█████████████████████████████████████████▍                                                  | 369/820 [2:44:14<2:59:41, 23.90s/it]

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:56<00:03,  3.53s/it]

{'eval_loss': 2.094888925552368, 'eval_runtime': 121.2092, 'eval_samples_per_second': 4.546, 'eval_steps_per_second': 0.289, 'epoch': 4.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.9617, 'learning_rate': 5.9528830581133734e-05, 'epoch': 4.51}

 45%|█████████████████████████████████████████▌                                                  | 371/820 [2:47:04<6:11:44, 49.68s/it]
{'loss': 2.0425, 'learning_rate': 5.933862302997615e-05, 'epoch': 4.52}

 45%|█████████████████████████████████████████▋                                                  | 372/820 [2:47:28<5:13:06, 41.93s/it]

 45%|█████████████████████████████████████████▊                                                  | 373/820 [2:47:52<4:33:26, 36.70s/it]

 46%|█████████████████████████████████████████▉                                                  | 374/820 [2:48:16<4:05:00, 32.96s/it]

 46%|██████████████████████████████████████████                                                  | 375/820 [2:48:41<3:45:49, 30.45s/it]

 46%|██████████████████████████████████████████▏                                                 | 376/820 [2:49:04<3:28:26, 28.17s/it]

 46%|██████████████████████████████████████████▎                                                 | 377/820 [2:49:28<3:19:53, 27.07s/it]

 46%|██████████████████████████████████████████▍                                                 | 378/820 [2:49:52<3:12:14, 26.10s/it]

 46%|██████████████████████████████████████████▌                                                 | 379/820 [2:50:17<3:08:20, 25.63s/it]

 46%|██████████████████████████████████████████▋                                                 | 380/820 [2:50:41<3:04:05, 25.10s/it]

 46%|██████████████████████████████████████████▋                                                 | 381/820 [2:51:05<3:02:04, 24.89s/it]

 47%|██████████████████████████████████████████▊                                                 | 382/820 [2:51:29<3:00:13, 24.69s/it]

 47%|██████████████████████████████████████████▉                                                 | 383/820 [2:51:53<2:58:14, 24.47s/it]

 47%|███████████████████████████████████████████                                                 | 384/820 [2:52:17<2:56:34, 24.30s/it]

 47%|███████████████████████████████████████████▏                                                | 385/820 [2:52:41<2:55:28, 24.20s/it]

 47%|███████████████████████████████████████████▎                                                | 386/820 [2:53:06<2:55:44, 24.30s/it]

 47%|███████████████████████████████████████████▍                                                | 387/820 [2:53:30<2:54:28, 24.18s/it]

 47%|███████████████████████████████████████████▌                                                | 388/820 [2:53:54<2:54:45, 24.27s/it]


 48%|███████████████████████████████████████████▊                                                | 390/820 [2:54:42<2:53:25, 24.20s/it]
{'loss': 2.0758, 'learning_rate': 5.570131979876142e-05, 'epoch': 4.76}

 48%|███████████████████████████████████████████▊                                                | 391/820 [2:55:06<2:51:08, 23.94s/it]

 48%|███████████████████████████████████████████▉                                                | 392/820 [2:55:30<2:51:40, 24.07s/it]

 48%|████████████████████████████████████████████                                                | 393/820 [2:55:53<2:48:25, 23.67s/it]

 48%|████████████████████████████████████████████▏                                               | 394/820 [2:56:17<2:49:25, 23.86s/it]

 48%|████████████████████████████████████████████▎                                               | 395/820 [2:56:42<2:50:23, 24.06s/it]

 48%|████████████████████████████████████████████▍                                               | 396/820 [2:57:06<2:50:31, 24.13s/it]


 49%|████████████████████████████████████████████▋                                               | 398/820 [2:57:55<2:50:35, 24.25s/it]
{'loss': 1.9853, 'learning_rate': 5.415944410197152e-05, 'epoch': 4.85}

 49%|████████████████████████████████████████████▊                                               | 399/820 [2:58:19<2:50:06, 24.24s/it]

 49%|████████████████████████████████████████████▉                                               | 400/820 [2:58:43<2:49:48, 24.26s/it]

 49%|████████████████████████████████████████████▉                                               | 401/820 [2:59:07<2:49:24, 24.26s/it]

 49%|█████████████████████████████████████████████                                               | 402/820 [2:59:32<2:48:55, 24.25s/it]

 49%|█████████████████████████████████████████████▏                                              | 403/820 [2:59:56<2:48:25, 24.23s/it]

 49%|█████████████████████████████████████████████▎                                              | 404/820 [3:00:20<2:48:40, 24.33s/it]


 50%|█████████████████████████████████████████████▌                                              | 406/820 [3:01:09<2:47:24, 24.26s/it]

 50%|█████████████████████████████████████████████▋                                              | 407/820 [3:01:33<2:46:38, 24.21s/it]
{'loss': 1.9942, 'learning_rate': 5.2420133432119537e-05, 'epoch': 4.96}

 50%|█████████████████████████████████████████████▊                                              | 408/820 [3:01:56<2:44:24, 23.94s/it]

 50%|█████████████████████████████████████████████▉                                              | 409/820 [3:02:20<2:43:48, 23.91s/it]

 50%|██████████████████████████████████████████████                                              | 410/820 [3:02:32<2:18:35, 20.28s/it]

































100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [01:58<00:00,  2.95s/it]

{'eval_loss': 2.0929973125457764, 'eval_runtime': 121.4322, 'eval_samples_per_second': 4.538, 'eval_steps_per_second': 0.288, 'epoch': 5.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.9626, 'learning_rate': 5.164603653748392e-05, 'epoch': 5.01}
 50%|██████████████████████████████████████████████                                              | 411/820 [3:04:58<6:35:56, 58.08s/it]

 50%|██████████████████████████████████████████████▏                                             | 412/820 [3:05:22<5:26:02, 47.95s/it]

 50%|██████████████████████████████████████████████▎                                             | 413/820 [3:05:46<4:36:24, 40.75s/it]

 50%|██████████████████████████████████████████████▍                                             | 414/820 [3:06:11<4:02:13, 35.80s/it]

 51%|██████████████████████████████████████████████▌                                             | 415/820 [3:06:35<3:37:52, 32.28s/it]

 51%|██████████████████████████████████████████████▋                                             | 416/820 [3:06:59<3:20:27, 29.77s/it]

 51%|██████████████████████████████████████████████▊                                             | 417/820 [3:07:22<3:08:08, 28.01s/it]

 51%|██████████████████████████████████████████████▉                                             | 418/820 [3:07:46<2:58:31, 26.64s/it]

 51%|███████████████████████████████████████████████                                             | 419/820 [3:08:10<2:53:19, 25.93s/it]


 51%|███████████████████████████████████████████████▏                                            | 421/820 [3:08:59<2:47:59, 25.26s/it]

 51%|███████████████████████████████████████████████▎                                            | 422/820 [3:09:23<2:45:07, 24.89s/it]
{'loss': 2.012, 'learning_rate': 4.9515791685021484e-05, 'epoch': 5.15}

 52%|███████████████████████████████████████████████▍                                            | 423/820 [3:09:47<2:41:23, 24.39s/it]

 52%|███████████████████████████████████████████████▌                                            | 424/820 [3:10:11<2:40:06, 24.26s/it]

 52%|███████████████████████████████████████████████▋                                            | 425/820 [3:10:35<2:39:01, 24.16s/it]

 52%|███████████████████████████████████████████████▊                                            | 426/820 [3:11:00<2:40:53, 24.50s/it]

 52%|███████████████████████████████████████████████▉                                            | 427/820 [3:11:24<2:40:41, 24.53s/it]

 52%|████████████████████████████████████████████████                                            | 428/820 [3:11:48<2:39:15, 24.38s/it]

 52%|████████████████████████████████████████████████▏                                           | 429/820 [3:12:13<2:39:05, 24.41s/it]

 52%|████████████████████████████████████████████████▏                                           | 430/820 [3:12:36<2:36:48, 24.12s/it]

 53%|████████████████████████████████████████████████▎                                           | 431/820 [3:13:00<2:36:07, 24.08s/it]

 53%|████████████████████████████████████████████████▍                                           | 432/820 [3:13:25<2:36:07, 24.14s/it]

 53%|████████████████████████████████████████████████▌                                           | 433/820 [3:13:49<2:35:35, 24.12s/it]

 53%|████████████████████████████████████████████████▋                                           | 434/820 [3:14:13<2:34:37, 24.04s/it]

 53%|████████████████████████████████████████████████▊                                           | 435/820 [3:14:37<2:35:27, 24.23s/it]

 53%|████████████████████████████████████████████████▉                                           | 436/820 [3:15:01<2:34:38, 24.16s/it]

 53%|█████████████████████████████████████████████████                                           | 437/820 [3:15:26<2:35:09, 24.31s/it]

 53%|█████████████████████████████████████████████████▏                                          | 438/820 [3:15:51<2:35:51, 24.48s/it]

 54%|█████████████████████████████████████████████████▎                                          | 439/820 [3:16:15<2:34:38, 24.35s/it]

 54%|█████████████████████████████████████████████████▎                                          | 440/820 [3:16:39<2:34:00, 24.32s/it]

 54%|█████████████████████████████████████████████████▍                                          | 441/820 [3:17:04<2:34:06, 24.40s/it]

 54%|█████████████████████████████████████████████████▌                                          | 442/820 [3:17:28<2:33:55, 24.43s/it]

 54%|█████████████████████████████████████████████████▋                                          | 443/820 [3:17:53<2:33:42, 24.46s/it]

 54%|█████████████████████████████████████████████████▊                                          | 444/820 [3:18:17<2:32:46, 24.38s/it]

 54%|█████████████████████████████████████████████████▉                                          | 445/820 [3:18:41<2:32:41, 24.43s/it]

 54%|██████████████████████████████████████████████████                                          | 446/820 [3:19:06<2:32:09, 24.41s/it]

 55%|██████████████████████████████████████████████████▏                                         | 447/820 [3:19:30<2:30:56, 24.28s/it]

 55%|██████████████████████████████████████████████████▎                                         | 448/820 [3:19:53<2:29:01, 24.04s/it]

 55%|██████████████████████████████████████████████████▍                                         | 449/820 [3:20:18<2:29:20, 24.15s/it]

 55%|██████████████████████████████████████████████████▍                                         | 450/820 [3:20:42<2:28:31, 24.09s/it]

 55%|██████████████████████████████████████████████████▌                                         | 451/820 [3:21:06<2:27:51, 24.04s/it]

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:57<00:03,  3.56s/it]

{'eval_loss': 2.1013760566711426, 'eval_runtime': 122.2194, 'eval_samples_per_second': 4.508, 'eval_steps_per_second': 0.286, 'epoch': 5.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.8195, 'learning_rate': 4.3721808946429025e-05, 'epoch': 5.51}
 55%|██████████████████████████████████████████████████▋                                         | 452/820 [3:23:33<6:14:13, 61.01s/it]

 55%|██████████████████████████████████████████████████▊                                         | 453/820 [3:23:57<5:06:01, 50.03s/it]

 55%|██████████████████████████████████████████████████▉                                         | 454/820 [3:24:22<4:18:50, 42.43s/it]

 55%|███████████████████████████████████████████████████                                         | 455/820 [3:24:45<3:43:13, 36.69s/it]

 56%|███████████████████████████████████████████████████▏                                        | 456/820 [3:25:09<3:19:23, 32.87s/it]

 56%|███████████████████████████████████████████████████▎                                        | 457/820 [3:25:34<3:04:02, 30.42s/it]

 56%|███████████████████████████████████████████████████▍                                        | 458/820 [3:25:58<2:52:42, 28.63s/it]

 56%|███████████████████████████████████████████████████▍                                        | 459/820 [3:26:23<2:45:42, 27.54s/it]

 56%|███████████████████████████████████████████████████▌                                        | 460/820 [3:26:49<2:41:19, 26.89s/it]

 56%|███████████████████████████████████████████████████▋                                        | 461/820 [3:27:13<2:36:33, 26.16s/it]

 56%|███████████████████████████████████████████████████▊                                        | 462/820 [3:27:38<2:33:03, 25.65s/it]

 56%|███████████████████████████████████████████████████▉                                        | 463/820 [3:28:02<2:29:48, 25.18s/it]

 57%|████████████████████████████████████████████████████                                        | 464/820 [3:28:26<2:28:01, 24.95s/it]

 57%|████████████████████████████████████████████████████▏                                       | 465/820 [3:28:49<2:23:53, 24.32s/it]

 57%|████████████████████████████████████████████████████▎                                       | 466/820 [3:29:13<2:23:39, 24.35s/it]

 57%|████████████████████████████████████████████████████▍                                       | 467/820 [3:29:38<2:23:50, 24.45s/it]

 57%|████████████████████████████████████████████████████▌                                       | 468/820 [3:30:03<2:23:21, 24.44s/it]

 57%|████████████████████████████████████████████████████▌                                       | 469/820 [3:30:27<2:23:17, 24.49s/it]

 57%|████████████████████████████████████████████████████▋                                       | 470/820 [3:30:52<2:22:59, 24.51s/it]

 57%|████████████████████████████████████████████████████▊                                       | 471/820 [3:31:16<2:21:31, 24.33s/it]

 58%|████████████████████████████████████████████████████▉                                       | 472/820 [3:31:40<2:20:27, 24.22s/it]

 58%|█████████████████████████████████████████████████████                                       | 473/820 [3:32:04<2:20:43, 24.33s/it]

 58%|█████████████████████████████████████████████████████▏                                      | 474/820 [3:32:29<2:20:52, 24.43s/it]

 58%|█████████████████████████████████████████████████████▎                                      | 475/820 [3:32:54<2:21:31, 24.61s/it]

 58%|█████████████████████████████████████████████████████▍                                      | 476/820 [3:33:19<2:21:15, 24.64s/it]

 58%|█████████████████████████████████████████████████████▌                                      | 477/820 [3:33:44<2:22:10, 24.87s/it]

 58%|█████████████████████████████████████████████████████▋                                      | 478/820 [3:34:09<2:21:28, 24.82s/it]

 58%|█████████████████████████████████████████████████████▋                                      | 479/820 [3:34:33<2:19:54, 24.62s/it]

 59%|█████████████████████████████████████████████████████▊                                      | 480/820 [3:34:57<2:19:16, 24.58s/it]

 59%|█████████████████████████████████████████████████████▉                                      | 481/820 [3:35:22<2:18:23, 24.50s/it]

 59%|██████████████████████████████████████████████████████                                      | 482/820 [3:35:46<2:17:50, 24.47s/it]

 59%|██████████████████████████████████████████████████████▏                                     | 483/820 [3:36:11<2:17:38, 24.51s/it]


 59%|██████████████████████████████████████████████████████▍                                     | 485/820 [3:36:59<2:16:21, 24.42s/it]
{'loss': 2.0306, 'learning_rate': 3.744922878484759e-05, 'epoch': 5.91}

 59%|██████████████████████████████████████████████████████▌                                     | 486/820 [3:37:23<2:14:22, 24.14s/it]


 60%|██████████████████████████████████████████████████████▊                                     | 488/820 [3:38:11<2:14:05, 24.23s/it]
{'loss': 2.0065, 'learning_rate': 3.68876335946898e-05, 'epoch': 5.95}

 60%|██████████████████████████████████████████████████████▊                                     | 489/820 [3:38:36<2:14:10, 24.32s/it]

 60%|██████████████████████████████████████████████████████▉                                     | 490/820 [3:39:00<2:13:11, 24.22s/it]

 60%|███████████████████████████████████████████████████████                                     | 491/820 [3:39:24<2:12:59, 24.25s/it]

 60%|███████████████████████████████████████████████████████▏                                    | 492/820 [3:39:37<1:53:05, 20.69s/it]

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [02:00<00:03,  3.73s/it]

{'eval_loss': 2.100202798843384, 'eval_runtime': 125.5181, 'eval_samples_per_second': 4.39, 'eval_steps_per_second': 0.279, 'epoch': 6.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.8994, 'learning_rate': 3.595561413333054e-05, 'epoch': 6.01}

 60%|███████████████████████████████████████████████████████▍                                    | 494/820 [3:42:32<4:27:02, 49.15s/it]

 60%|███████████████████████████████████████████████████████▌                                    | 495/820 [3:42:56<3:45:12, 41.58s/it]

 60%|███████████████████████████████████████████████████████▋                                    | 496/820 [3:43:20<3:16:04, 36.31s/it]

 61%|███████████████████████████████████████████████████████▊                                    | 497/820 [3:43:44<2:55:18, 32.56s/it]
{'loss': 2.0431, 'learning_rate': 3.521377516939997e-05, 'epoch': 6.06}

 61%|███████████████████████████████████████████████████████▊                                    | 498/820 [3:44:08<2:41:53, 30.17s/it]

 61%|███████████████████████████████████████████████████████▉                                    | 499/820 [3:44:33<2:32:33, 28.51s/it]

 61%|████████████████████████████████████████████████████████                                    | 500/820 [3:44:58<2:27:08, 27.59s/it]

 61%|████████████████████████████████████████████████████████▏                                   | 501/820 [3:45:22<2:21:08, 26.55s/it]

 61%|████████████████████████████████████████████████████████▎                                   | 502/820 [3:45:46<2:16:27, 25.75s/it]


 61%|████████████████████████████████████████████████████████▌                                   | 504/820 [3:46:34<2:10:34, 24.79s/it]
{'loss': 2.0229, 'learning_rate': 3.392420579877149e-05, 'epoch': 6.15}

 62%|████████████████████████████████████████████████████████▋                                   | 505/820 [3:46:59<2:09:38, 24.69s/it]

 62%|████████████████████████████████████████████████████████▊                                   | 506/820 [3:47:23<2:08:26, 24.54s/it]

 62%|████████████████████████████████████████████████████████▉                                   | 507/820 [3:47:49<2:11:23, 25.19s/it]

 62%|████████████████████████████████████████████████████████▉                                   | 508/820 [3:48:15<2:10:49, 25.16s/it]


 62%|█████████████████████████████████████████████████████████▏                                  | 510/820 [3:49:04<2:09:11, 25.01s/it]
{'loss': 2.0597, 'learning_rate': 3.2828232294918826e-05, 'epoch': 6.22}

 62%|█████████████████████████████████████████████████████████▎                                  | 511/820 [3:49:29<2:08:08, 24.88s/it]

 62%|█████████████████████████████████████████████████████████▍                                  | 512/820 [3:49:53<2:07:05, 24.76s/it]


 63%|█████████████████████████████████████████████████████████▋                                  | 514/820 [3:50:42<2:05:35, 24.63s/it]
{'loss': 1.9091, 'learning_rate': 3.2102700227213776e-05, 'epoch': 6.27}

 63%|█████████████████████████████████████████████████████████▊                                  | 515/820 [3:51:07<2:05:08, 24.62s/it]

 63%|█████████████████████████████████████████████████████████▉                                  | 516/820 [3:51:32<2:04:42, 24.62s/it]


 63%|██████████████████████████████████████████████████████████                                  | 518/820 [3:52:20<2:03:13, 24.48s/it]

 63%|██████████████████████████████████████████████████████████▏                                 | 519/820 [3:52:44<2:02:08, 24.35s/it]
{'loss': 2.0133, 'learning_rate': 3.1201847995801964e-05, 'epoch': 6.33}

 63%|██████████████████████████████████████████████████████████▎                                 | 520/820 [3:53:09<2:02:10, 24.44s/it]

 64%|██████████████████████████████████████████████████████████▍                                 | 521/820 [3:53:34<2:01:53, 24.46s/it]

 64%|██████████████████████████████████████████████████████████▌                                 | 522/820 [3:53:57<2:00:07, 24.19s/it]

 64%|██████████████████████████████████████████████████████████▋                                 | 523/820 [3:54:21<1:59:59, 24.24s/it]

 64%|██████████████████████████████████████████████████████████▊                                 | 524/820 [3:54:46<1:59:57, 24.32s/it]

 64%|██████████████████████████████████████████████████████████▉                                 | 525/820 [3:55:09<1:58:20, 24.07s/it]

 64%|███████████████████████████████████████████████████████████                                 | 526/820 [3:55:34<1:58:22, 24.16s/it]

 64%|███████████████████████████████████████████████████████████▏                                | 527/820 [3:55:58<1:57:55, 24.15s/it]


 65%|███████████████████████████████████████████████████████████▎                                | 529/820 [3:56:47<1:57:41, 24.27s/it]
{'loss': 1.9356, 'learning_rate': 2.9421634208822772e-05, 'epoch': 6.45}

 65%|███████████████████████████████████████████████████████████▍                                | 530/820 [3:57:11<1:57:42, 24.35s/it]

 65%|███████████████████████████████████████████████████████████▌                                | 531/820 [3:57:36<1:57:34, 24.41s/it]


 65%|███████████████████████████████████████████████████████████▊                                | 533/820 [3:58:25<1:56:55, 24.44s/it]
{'loss': 1.9559, 'learning_rate': 2.8718045783377223e-05, 'epoch': 6.5}

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [02:00<00:03,  3.56s/it]

{'eval_loss': 2.1073858737945557, 'eval_runtime': 125.8448, 'eval_samples_per_second': 4.378, 'eval_steps_per_second': 0.278, 'epoch': 6.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.9042, 'learning_rate': 2.854294046896149e-05, 'epoch': 6.51}
 65%|███████████████████████████████████████████████████████████▉                                | 534/820 [4:00:55<4:57:16, 62.36s/it]

 65%|████████████████████████████████████████████████████████████                                | 535/820 [4:01:20<4:02:04, 50.96s/it]

 65%|████████████████████████████████████████████████████████████▏                               | 536/820 [4:01:44<3:22:58, 42.88s/it]

 65%|████████████████████████████████████████████████████████████▏                               | 537/820 [4:02:08<2:56:21, 37.39s/it]

 66%|████████████████████████████████████████████████████████████▎                               | 538/820 [4:02:33<2:37:11, 33.45s/it]

 66%|████████████████████████████████████████████████████████████▍                               | 539/820 [4:02:58<2:25:50, 31.14s/it]


 66%|████████████████████████████████████████████████████████████▋                               | 541/820 [4:03:47<2:08:43, 27.68s/it]
{'loss': 1.8802, 'learning_rate': 2.7326365214272753e-05, 'epoch': 6.6}

 66%|████████████████████████████████████████████████████████████▊                               | 542/820 [4:04:11<2:03:46, 26.71s/it]

 66%|████████████████████████████████████████████████████████████▉                               | 543/820 [4:04:36<2:00:04, 26.01s/it]

 66%|█████████████████████████████████████████████████████████████                               | 544/820 [4:05:00<1:57:44, 25.59s/it]


 67%|█████████████████████████████████████████████████████████████▎                              | 546/820 [4:05:49<1:54:15, 25.02s/it]

 67%|█████████████████████████████████████████████████████████████▎                              | 547/820 [4:06:13<1:52:22, 24.70s/it]

 67%|█████████████████████████████████████████████████████████████▍                              | 548/820 [4:06:37<1:51:00, 24.49s/it]

 67%|█████████████████████████████████████████████████████████████▌                              | 549/820 [4:07:01<1:49:55, 24.34s/it]
{'loss': 2.0313, 'learning_rate': 2.5956457952401715e-05, 'epoch': 6.7}

 67%|█████████████████████████████████████████████████████████████▋                              | 550/820 [4:07:26<1:49:44, 24.39s/it]

 67%|█████████████████████████████████████████████████████████████▊                              | 551/820 [4:07:51<1:49:41, 24.47s/it]

 67%|█████████████████████████████████████████████████████████████▉                              | 552/820 [4:08:15<1:49:07, 24.43s/it]

 67%|██████████████████████████████████████████████████████████████                              | 553/820 [4:08:39<1:48:33, 24.39s/it]


 68%|██████████████████████████████████████████████████████████████▎                             | 555/820 [4:09:28<1:47:23, 24.31s/it]
{'loss': 1.9083, 'learning_rate': 2.4944108422707014e-05, 'epoch': 6.77}

 68%|██████████████████████████████████████████████████████████████▍                             | 556/820 [4:09:53<1:47:46, 24.49s/it]

 68%|██████████████████████████████████████████████████████████████▍                             | 557/820 [4:10:17<1:47:03, 24.42s/it]

 68%|██████████████████████████████████████████████████████████████▌                             | 558/820 [4:10:41<1:46:04, 24.29s/it]

 68%|██████████████████████████████████████████████████████████████▋                             | 559/820 [4:11:05<1:45:12, 24.19s/it]

 68%|██████████████████████████████████████████████████████████████▊                             | 560/820 [4:11:29<1:45:03, 24.24s/it]

 68%|██████████████████████████████████████████████████████████████▉                             | 561/820 [4:11:53<1:44:43, 24.26s/it]


 69%|███████████████████████████████████████████████████████████████▏                            | 563/820 [4:12:42<1:43:49, 24.24s/it]
{'loss': 1.9352, 'learning_rate': 2.361545660544084e-05, 'epoch': 6.87}

 69%|███████████████████████████████████████████████████████████████▎                            | 564/820 [4:13:06<1:43:48, 24.33s/it]

 69%|███████████████████████████████████████████████████████████████▍                            | 565/820 [4:13:31<1:43:31, 24.36s/it]


 69%|███████████████████████████████████████████████████████████████▌                            | 567/820 [4:14:20<1:42:59, 24.42s/it]
{'loss': 2.056, 'learning_rate': 2.2960553213161774e-05, 'epoch': 6.91}


 69%|███████████████████████████████████████████████████████████████▊                            | 569/820 [4:15:08<1:41:38, 24.30s/it]

 70%|███████████████████████████████████████████████████████████████▉                            | 570/820 [4:15:32<1:41:20, 24.32s/it]

 70%|████████████████████████████████████████████████████████████████                            | 571/820 [4:15:57<1:40:55, 24.32s/it]
{'loss': 1.8794, 'learning_rate': 2.231214165078943e-05, 'epoch': 6.96}

 70%|████████████████████████████████████████████████████████████████▏                           | 572/820 [4:16:21<1:40:33, 24.33s/it]

 70%|████████████████████████████████████████████████████████████████▎                           | 573/820 [4:16:45<1:39:46, 24.23s/it]

 70%|████████████████████████████████████████████████████████████████▍                           | 574/820 [4:16:58<1:25:06, 20.76s/it]


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:57<00:03,  3.55s/it]
{'eval_loss': 2.1070709228515625, 'eval_runtime': 122.6171, 'eval_samples_per_second': 4.494, 'eval_steps_per_second': 0.285, 'epoch': 7.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 70%|████████████████████████████████████████████████████████████████▌                           | 575/820 [4:19:25<3:59:38, 58.69s/it]

 70%|████████████████████████████████████████████████████████████████▌                           | 576/820 [4:19:50<3:18:00, 48.69s/it]
{'loss': 1.9912, 'learning_rate': 2.1510993343990792e-05, 'epoch': 7.02}


 70%|████████████████████████████████████████████████████████████████▊                           | 578/820 [4:20:41<2:28:21, 36.78s/it]
{'loss': 1.9983, 'learning_rate': 2.1193509725830275e-05, 'epoch': 7.05}


 71%|█████████████████████████████████████████████████████████████████                           | 580/820 [4:21:31<2:02:38, 30.66s/it]

 71%|█████████████████████████████████████████████████████████████████▏                          | 581/820 [4:21:55<1:54:43, 28.80s/it]

 71%|█████████████████████████████████████████████████████████████████▎                          | 582/820 [4:22:19<1:48:25, 27.33s/it]
{'loss': 1.9589, 'learning_rate': 2.0563748575861647e-05, 'epoch': 7.1}

 71%|█████████████████████████████████████████████████████████████████▍                          | 583/820 [4:22:43<1:44:39, 26.49s/it]

 71%|█████████████████████████████████████████████████████████████████▌                          | 584/820 [4:23:08<1:41:46, 25.87s/it]

 71%|█████████████████████████████████████████████████████████████████▋                          | 585/820 [4:23:32<1:39:18, 25.35s/it]

 71%|█████████████████████████████████████████████████████████████████▋                          | 586/820 [4:23:56<1:37:29, 25.00s/it]

 72%|█████████████████████████████████████████████████████████████████▊                          | 587/820 [4:24:22<1:37:25, 25.09s/it]


 72%|██████████████████████████████████████████████████████████████████                          | 589/820 [4:25:11<1:35:49, 24.89s/it]

 72%|██████████████████████████████████████████████████████████████████▏                         | 590/820 [4:25:35<1:34:40, 24.70s/it]

 72%|██████████████████████████████████████████████████████████████████▎                         | 591/820 [4:25:59<1:33:24, 24.48s/it]

 72%|██████████████████████████████████████████████████████████████████▍                         | 592/820 [4:26:23<1:32:30, 24.34s/it]

 72%|██████████████████████████████████████████████████████████████████▌                         | 593/820 [4:26:47<1:31:45, 24.25s/it]
{'loss': 1.9699, 'learning_rate': 1.8868794731662325e-05, 'epoch': 7.23}

 72%|██████████████████████████████████████████████████████████████████▋                         | 594/820 [4:27:10<1:30:16, 23.97s/it]

 73%|██████████████████████████████████████████████████████████████████▊                         | 595/820 [4:27:36<1:31:48, 24.48s/it]


 73%|██████████████████████████████████████████████████████████████████▉                         | 597/820 [4:28:27<1:32:43, 24.95s/it]

 73%|███████████████████████████████████████████████████████████████████                         | 598/820 [4:28:51<1:31:40, 24.78s/it]

 73%|███████████████████████████████████████████████████████████████████▏                        | 599/820 [4:29:15<1:30:28, 24.56s/it]

 73%|███████████████████████████████████████████████████████████████████▎                        | 600/820 [4:29:39<1:29:19, 24.36s/it]
{'loss': 2.0607, 'learning_rate': 1.7819423586947497e-05, 'epoch': 7.32}

 73%|███████████████████████████████████████████████████████████████████▍                        | 601/820 [4:30:04<1:29:02, 24.40s/it]

 73%|███████████████████████████████████████████████████████████████████▌                        | 602/820 [4:30:28<1:28:48, 24.44s/it]


 74%|███████████████████████████████████████████████████████████████████▊                        | 604/820 [4:31:17<1:27:48, 24.39s/it]

 74%|███████████████████████████████████████████████████████████████████▉                        | 605/820 [4:31:42<1:27:44, 24.49s/it]

 74%|███████████████████████████████████████████████████████████████████▉                        | 606/820 [4:32:07<1:28:25, 24.79s/it]
{'loss': 1.9746, 'learning_rate': 1.6938765545419736e-05, 'epoch': 7.39}

 74%|████████████████████████████████████████████████████████████████████                        | 607/820 [4:32:32<1:28:04, 24.81s/it]

 74%|████████████████████████████████████████████████████████████████████▏                       | 608/820 [4:32:56<1:27:18, 24.71s/it]

 74%|████████████████████████████████████████████████████████████████████▎                       | 609/820 [4:33:20<1:26:13, 24.52s/it]

 74%|████████████████████████████████████████████████████████████████████▍                       | 610/820 [4:33:44<1:25:08, 24.33s/it]

 75%|████████████████████████████████████████████████████████████████████▌                       | 611/820 [4:34:09<1:24:39, 24.30s/it]


 75%|████████████████████████████████████████████████████████████████████▊                       | 613/820 [4:34:57<1:23:54, 24.32s/it]

 75%|████████████████████████████████████████████████████████████████████▉                       | 614/820 [4:35:21<1:23:06, 24.21s/it]

 75%|█████████████████████████████████████████████████████████████████████                       | 615/820 [4:35:45<1:22:27, 24.14s/it]
{'loss': 1.9624, 'learning_rate': 1.5651410363335882e-05, 'epoch': 7.5}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [02:05<00:03,  3.57s/it]
{'eval_loss': 2.112027406692505, 'eval_runtime': 130.3002, 'eval_samples_per_second': 4.229, 'eval_steps_per_second': 0.269, 'epoch': 7.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 75%|█████████████████████████████████████████████████████████████████████                       | 616/820 [4:38:20<3:35:31, 63.39s/it]

 75%|█████████████████████████████████████████████████████████████████████▏                      | 617/820 [4:38:44<2:54:22, 51.54s/it]
{'loss': 1.9135, 'learning_rate': 1.537094644749303e-05, 'epoch': 7.52}

 75%|█████████████████████████████████████████████████████████████████████▎                      | 618/820 [4:39:09<2:26:16, 43.45s/it]


 76%|█████████████████████████████████████████████████████████████████████▌                      | 620/820 [4:39:56<1:51:18, 33.39s/it]

 76%|█████████████████████████████████████████████████████████████████████▋                      | 621/820 [4:40:20<1:40:57, 30.44s/it]

 76%|█████████████████████████████████████████████████████████████████████▊                      | 622/820 [4:40:46<1:35:45, 29.02s/it]

 76%|█████████████████████████████████████████████████████████████████████▉                      | 623/820 [4:41:10<1:30:54, 27.69s/it]
{'loss': 1.9389, 'learning_rate': 1.4542092597214729e-05, 'epoch': 7.6}

 76%|██████████████████████████████████████████████████████████████████████                      | 624/820 [4:41:35<1:27:13, 26.70s/it]

 76%|██████████████████████████████████████████████████████████████████████                      | 625/820 [4:41:59<1:24:29, 26.00s/it]

 76%|██████████████████████████████████████████████████████████████████████▏                     | 626/820 [4:42:23<1:22:09, 25.41s/it]


 77%|██████████████████████████████████████████████████████████████████████▍                     | 628/820 [4:43:12<1:19:48, 24.94s/it]
{'loss': 1.9349, 'learning_rate': 1.3865993709689318e-05, 'epoch': 7.66}

 77%|██████████████████████████████████████████████████████████████████████▌                     | 629/820 [4:43:37<1:19:15, 24.90s/it]


 77%|██████████████████████████████████████████████████████████████████████▊                     | 631/820 [4:44:26<1:17:49, 24.71s/it]

 77%|██████████████████████████████████████████████████████████████████████▉                     | 632/820 [4:44:50<1:17:13, 24.65s/it]

 77%|███████████████████████████████████████████████████████████████████████                     | 633/820 [4:45:16<1:17:48, 24.97s/it]

 77%|███████████████████████████████████████████████████████████████████████▏                    | 634/820 [4:45:40<1:16:46, 24.76s/it]
{'loss': 1.9048, 'learning_rate': 1.3072589650649486e-05, 'epoch': 7.73}

 77%|███████████████████████████████████████████████████████████████████████▏                    | 635/820 [4:46:03<1:14:26, 24.14s/it]

 78%|███████████████████████████████████████████████████████████████████████▎                    | 636/820 [4:46:27<1:14:11, 24.19s/it]


 78%|███████████████████████████████████████████████████████████████████████▌                    | 638/820 [4:47:16<1:13:47, 24.33s/it]

 78%|███████████████████████████████████████████████████████████████████████▋                    | 639/820 [4:47:40<1:13:13, 24.28s/it]
{'loss': 1.9507, 'learning_rate': 1.2426639456946398e-05, 'epoch': 7.79}


 78%|███████████████████████████████████████████████████████████████████████▉                    | 641/820 [4:48:30<1:13:28, 24.63s/it]

 78%|████████████████████████████████████████████████████████████████████████                    | 642/820 [4:48:55<1:12:53, 24.57s/it]

 78%|████████████████████████████████████████████████████████████████████████▏                   | 643/820 [4:49:19<1:11:57, 24.39s/it]

 79%|████████████████████████████████████████████████████████████████████████▎                   | 644/820 [4:49:43<1:11:05, 24.24s/it]

 79%|████████████████████████████████████████████████████████████████████████▎                   | 645/820 [4:50:07<1:10:48, 24.28s/it]
{'loss': 1.8902, 'learning_rate': 1.1670125552660116e-05, 'epoch': 7.87}


 79%|████████████████████████████████████████████████████████████████████████▌                   | 647/820 [4:50:56<1:10:21, 24.40s/it]

 79%|████████████████████████████████████████████████████████████████████████▋                   | 648/820 [4:51:21<1:09:59, 24.42s/it]
{'loss': 1.9855, 'learning_rate': 1.1299607925160915e-05, 'epoch': 7.9}

 79%|████████████████████████████████████████████████████████████████████████▊                   | 649/820 [4:51:45<1:09:56, 24.54s/it]

 79%|████████████████████████████████████████████████████████████████████████▉                   | 650/820 [4:52:10<1:09:29, 24.53s/it]


 80%|█████████████████████████████████████████████████████████████████████████▏                  | 652/820 [4:52:59<1:08:32, 24.48s/it]

 80%|█████████████████████████████████████████████████████████████████████████▎                  | 653/820 [4:53:23<1:08:00, 24.43s/it]

 80%|█████████████████████████████████████████████████████████████████████████▍                  | 654/820 [4:53:47<1:07:28, 24.39s/it]
{'loss': 1.9697, 'learning_rate': 1.0574301505337203e-05, 'epoch': 7.98}


 80%|███████████████████████████████████████████████████████████████████████████▏                  | 656/820 [4:54:23<55:58, 20.48s/it]
{'loss': 2.0429, 'learning_rate': 1.03372463680101e-05, 'epoch': 8.0}

































 94%|████████████████████████████████████████████████████████████████████████████████████████████▍     | 33/35 [01:59<00:07,  3.61s/it]
{'eval_loss': 2.1128270626068115, 'eval_runtime': 128.2277, 'eval_samples_per_second': 4.297, 'eval_steps_per_second': 0.273, 'epoch': 8.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 80%|█████████████████████████████████████████████████████████████████████████▋                  | 657/820 [4:56:56<2:44:01, 60.38s/it]
{'loss': 1.9219, 'learning_rate': 1.0219610665886038e-05, 'epoch': 8.01}

 80%|█████████████████████████████████████████████████████████████████████████▊                  | 658/820 [4:57:20<2:12:56, 49.24s/it]

 80%|█████████████████████████████████████████████████████████████████████████▉                  | 659/820 [4:57:44<1:51:47, 41.66s/it]

 80%|██████████████████████████████████████████████████████████████████████████                  | 660/820 [4:58:08<1:37:16, 36.48s/it]


 81%|██████████████████████████████████████████████████████████████████████████▎                 | 662/820 [4:58:58<1:20:32, 30.59s/it]
{'loss': 1.9528, 'learning_rate': 9.640421159695202e-06, 'epoch': 8.07}


 81%|██████████████████████████████████████████████████████████████████████████▍                 | 664/820 [4:59:48<1:12:07, 27.74s/it]

 81%|██████████████████████████████████████████████████████████████████████████▌                 | 665/820 [5:00:12<1:08:47, 26.63s/it]
{'loss': 1.9555, 'learning_rate': 9.300161073198322e-06, 'epoch': 8.11}

 81%|██████████████████████████████████████████████████████████████████████████▋                 | 666/820 [5:00:36<1:06:36, 25.95s/it]


 81%|██████████████████████████████████████████████████████████████████████████▉                 | 668/820 [5:01:23<1:02:43, 24.76s/it]

 82%|███████████████████████████████████████████████████████████████████████████                 | 669/820 [5:01:47<1:01:39, 24.50s/it]

 82%|███████████████████████████████████████████████████████████████████████████▏                | 670/820 [5:02:12<1:01:19, 24.53s/it]

 82%|███████████████████████████████████████████████████████████████████████████▎                | 671/820 [5:02:37<1:01:22, 24.71s/it]
{'loss': 1.9972, 'learning_rate': 8.636175690509396e-06, 'epoch': 8.18}


 82%|███████████████████████████████████████████████████████████████████████████▌                | 673/820 [5:03:28<1:01:23, 25.06s/it]

 82%|███████████████████████████████████████████████████████████████████████████▌                | 674/820 [5:03:54<1:01:43, 25.37s/it]
{'loss': 1.9532, 'learning_rate': 8.312540065764268e-06, 'epoch': 8.22}


 82%|█████████████████████████████████████████████████████████████████████████████▍                | 676/820 [5:04:43<59:53, 24.95s/it]

 83%|█████████████████████████████████████████████████████████████████████████████▌                | 677/820 [5:05:07<58:57, 24.74s/it]

 83%|█████████████████████████████████████████████████████████████████████████████▋                | 678/820 [5:05:32<58:22, 24.67s/it]

 83%|█████████████████████████████████████████████████████████████████████████████▊                | 679/820 [5:05:56<57:42, 24.56s/it]
{'loss': 1.971, 'learning_rate': 7.785679498355431e-06, 'epoch': 8.28}


 83%|██████████████████████████████████████████████████████████████████████████████                | 681/820 [5:06:45<56:50, 24.54s/it]

 83%|██████████████████████████████████████████████████████████████████████████████▏               | 682/820 [5:07:12<57:44, 25.11s/it]
{'loss': 1.9627, 'learning_rate': 7.477152013699118e-06, 'epoch': 8.32}

 83%|██████████████████████████████████████████████████████████████████████████████▎               | 683/820 [5:07:37<57:38, 25.25s/it]


 84%|██████████████████████████████████████████████████████████████████████████████▌               | 685/820 [5:08:28<56:34, 25.14s/it]

 84%|██████████████████████████████████████████████████████████████████████████████▋               | 686/820 [5:08:52<55:42, 24.95s/it]

 84%|██████████████████████████████████████████████████████████████████████████████▊               | 687/820 [5:09:16<54:38, 24.65s/it]
{'loss': 1.868, 'learning_rate': 6.9757213751356745e-06, 'epoch': 8.38}

 84%|██████████████████████████████████████████████████████████████████████████████▊               | 688/820 [5:09:39<53:17, 24.22s/it]

 84%|██████████████████████████████████████████████████████████████████████████████▉               | 689/820 [5:10:03<52:52, 24.22s/it]


 84%|███████████████████████████████████████████████████████████████████████████████▏              | 691/820 [5:10:52<52:04, 24.22s/it]
{'loss': 2.1013, 'learning_rate': 6.5861886920116965e-06, 'epoch': 8.43}


 85%|███████████████████████████████████████████████████████████████████████████████▍              | 693/820 [5:11:38<50:14, 23.73s/it]

 85%|███████████████████████████████████████████████████████████████████████████████▌              | 694/820 [5:12:04<51:02, 24.31s/it]

 85%|███████████████████████████████████████████████████████████████████████████████▋              | 695/820 [5:12:28<50:43, 24.35s/it]

 85%|███████████████████████████████████████████████████████████████████████████████▊              | 696/820 [5:12:54<50:52, 24.62s/it]
{'loss': 1.9232, 'learning_rate': 6.113941055604505e-06, 'epoch': 8.49}

 85%|███████████████████████████████████████████████████████████████████████████████▉              | 697/820 [5:13:18<50:02, 24.41s/it]


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [01:56<00:03,  3.55s/it]
{'eval_loss': 2.1149871349334717, 'eval_runtime': 121.8604, 'eval_samples_per_second': 4.522, 'eval_steps_per_second': 0.287, 'epoch': 8.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 85%|██████████████████████████████████████████████████████████████████████████████▎             | 698/820 [5:15:45<2:04:28, 61.21s/it]

 85%|██████████████████████████████████████████████████████████████████████████████▍             | 699/820 [5:16:09<1:40:54, 50.04s/it]
{'loss': 2.0059, 'learning_rate': 5.838483669686623e-06, 'epoch': 8.52}

 85%|██████████████████████████████████████████████████████████████████████████████▌             | 700/820 [5:16:33<1:24:49, 42.42s/it]


 86%|██████████████████████████████████████████████████████████████████████████████▊             | 702/820 [5:17:22<1:05:14, 33.17s/it]

 86%|████████████████████████████████████████████████████████████████████████████████▌             | 703/820 [5:17:46<59:17, 30.41s/it]

 86%|████████████████████████████████████████████████████████████████████████████████▋             | 704/820 [5:18:10<55:21, 28.64s/it]

 86%|████████████████████████████████████████████████████████████████████████████████▊             | 705/820 [5:18:34<51:50, 27.05s/it]

 86%|████████████████████████████████████████████████████████████████████████████████▉             | 706/820 [5:18:58<50:04, 26.35s/it]

 86%|█████████████████████████████████████████████████████████████████████████████████             | 707/820 [5:19:24<49:32, 26.30s/it]

 86%|█████████████████████████████████████████████████████████████████████████████████▏            | 708/820 [5:19:49<48:01, 25.73s/it]

 86%|█████████████████████████████████████████████████████████████████████████████████▎            | 709/820 [5:20:13<46:36, 25.20s/it]
{'loss': 2.0013, 'learning_rate': 4.963568839122679e-06, 'epoch': 8.65}


 87%|█████████████████████████████████████████████████████████████████████████████████▌            | 711/820 [5:21:02<45:06, 24.83s/it]

 87%|█████████████████████████████████████████████████████████████████████████████████▌            | 712/820 [5:21:26<44:33, 24.76s/it]

 87%|█████████████████████████████████████████████████████████████████████████████████▋            | 713/820 [5:21:50<43:44, 24.53s/it]

 87%|█████████████████████████████████████████████████████████████████████████████████▊            | 714/820 [5:22:14<43:00, 24.35s/it]

 87%|█████████████████████████████████████████████████████████████████████████████████▉            | 715/820 [5:22:39<42:52, 24.50s/it]

 87%|██████████████████████████████████████████████████████████████████████████████████            | 716/820 [5:23:05<43:10, 24.91s/it]

 87%|██████████████████████████████████████████████████████████████████████████████████▏           | 717/820 [5:23:29<42:31, 24.77s/it]

 88%|██████████████████████████████████████████████████████████████████████████████████▎           | 718/820 [5:23:53<41:41, 24.52s/it]
{'loss': 2.089, 'learning_rate': 4.233884348519384e-06, 'epoch': 8.76}


 88%|██████████████████████████████████████████████████████████████████████████████████▌           | 720/820 [5:24:41<40:12, 24.13s/it]

 88%|██████████████████████████████████████████████████████████████████████████████████▋           | 721/820 [5:25:06<39:59, 24.24s/it]

 88%|██████████████████████████████████████████████████████████████████████████████████▊           | 722/820 [5:25:30<39:39, 24.28s/it]
{'loss': 1.7482, 'learning_rate': 3.9273836922938345e-06, 'epoch': 8.8}


 88%|██████████████████████████████████████████████████████████████████████████████████▉           | 724/820 [5:26:19<38:59, 24.37s/it]

 88%|███████████████████████████████████████████████████████████████████████████████████           | 725/820 [5:26:44<39:11, 24.76s/it]

 89%|███████████████████████████████████████████████████████████████████████████████████▏          | 726/820 [5:27:10<38:59, 24.88s/it]

 89%|███████████████████████████████████████████████████████████████████████████████████▎          | 727/820 [5:27:33<37:46, 24.37s/it]

 89%|███████████████████████████████████████████████████████████████████████████████████▍          | 728/820 [5:27:57<37:26, 24.42s/it]

 89%|███████████████████████████████████████████████████████████████████████████████████▌          | 729/820 [5:28:22<37:07, 24.48s/it]

 89%|███████████████████████████████████████████████████████████████████████████████████▋          | 730/820 [5:28:46<36:42, 24.47s/it]

 89%|███████████████████████████████████████████████████████████████████████████████████▊          | 731/820 [5:29:10<36:02, 24.30s/it]
{'loss': 1.9572, 'learning_rate': 3.2783084608772443e-06, 'epoch': 8.91}


 89%|████████████████████████████████████████████████████████████████████████████████████          | 733/820 [5:30:00<35:35, 24.54s/it]

 90%|████████████████████████████████████████████████████████████████████████████████████▏         | 734/820 [5:30:23<34:42, 24.22s/it]

 90%|████████████████████████████████████████████████████████████████████████████████████▎         | 735/820 [5:30:48<34:26, 24.32s/it]

 90%|████████████████████████████████████████████████████████████████████████████████████▎         | 736/820 [5:31:12<34:02, 24.32s/it]
{'loss': 1.9568, 'learning_rate': 2.9421992479618634e-06, 'epoch': 8.98}


 90%|████████████████████████████████████████████████████████████████████████████████████▌         | 738/820 [5:31:48<28:06, 20.57s/it]
{'loss': 2.0484, 'learning_rate': 2.8126915364127147e-06, 'epoch': 9.0}

































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [02:01<00:03,  3.69s/it]

{'eval_loss': 2.1148488521575928, 'eval_runtime': 126.3392, 'eval_samples_per_second': 4.361, 'eval_steps_per_second': 0.277, 'epoch': 9.0}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 90%|██████████████████████████████████████████████████████████████████████████████████▉         | 739/820 [5:34:20<1:20:56, 59.96s/it]
{'loss': 1.8441, 'learning_rate': 2.7489993183614782e-06, 'epoch': 9.01}


 90%|████████████████████████████████████████████████████████████████████████████████████▉         | 741/820 [5:35:09<55:03, 41.82s/it]

 90%|█████████████████████████████████████████████████████████████████████████████████████         | 742/820 [5:35:33<47:40, 36.67s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▏        | 743/820 [5:35:57<42:09, 32.85s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▎        | 744/820 [5:36:22<38:27, 30.36s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▍        | 745/820 [5:36:46<35:32, 28.43s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▌        | 746/820 [5:37:10<33:35, 27.23s/it]
{'loss': 2.0041, 'learning_rate': 2.3230589895522405e-06, 'epoch': 9.1}


 91%|█████████████████████████████████████████████████████████████████████████████████████▋        | 748/820 [5:37:59<30:59, 25.82s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▊        | 749/820 [5:38:23<29:59, 25.35s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▉        | 750/820 [5:38:48<29:12, 25.04s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████        | 751/820 [5:39:12<28:26, 24.73s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▏       | 752/820 [5:39:36<27:45, 24.49s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▎       | 753/820 [5:40:00<27:11, 24.36s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▍       | 754/820 [5:40:23<26:25, 24.02s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▌       | 755/820 [5:40:50<26:52, 24.80s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▋       | 756/820 [5:41:14<26:24, 24.76s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▊       | 757/820 [5:41:39<25:56, 24.71s/it]

 92%|██████████████████████████████████████████████████████████████████████████████████████▉       | 758/820 [5:42:03<25:23, 24.57s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████       | 759/820 [5:42:27<24:54, 24.50s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████       | 760/820 [5:42:52<24:26, 24.45s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▏      | 761/820 [5:43:16<24:02, 24.44s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▎      | 762/820 [5:43:40<23:35, 24.40s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▍      | 763/820 [5:44:05<23:10, 24.40s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▌      | 764/820 [5:44:30<22:56, 24.58s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▋      | 765/820 [5:44:54<22:23, 24.42s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▊      | 766/820 [5:45:18<21:57, 24.39s/it]

 94%|███████████████████████████████████████████████████████████████████████████████████████▉      | 767/820 [5:45:42<21:23, 24.23s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████      | 768/820 [5:46:06<21:00, 24.23s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████▏     | 769/820 [5:46:31<20:37, 24.26s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████▎     | 770/820 [5:46:55<20:08, 24.17s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████▍     | 771/820 [5:47:19<19:50, 24.29s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████▍     | 772/820 [5:47:44<19:28, 24.34s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████▌     | 773/820 [5:48:09<19:15, 24.59s/it]

 94%|████████████████████████████████████████████████████████████████████████████████████████▋     | 774/820 [5:48:33<18:47, 24.51s/it]

 95%|████████████████████████████████████████████████████████████████████████████████████████▊     | 775/820 [5:48:58<18:23, 24.52s/it]

 95%|████████████████████████████████████████████████████████████████████████████████████████▉     | 776/820 [5:49:22<17:51, 24.34s/it]

 95%|█████████████████████████████████████████████████████████████████████████████████████████     | 777/820 [5:49:46<17:29, 24.41s/it]

 95%|█████████████████████████████████████████████████████████████████████████████████████████▏    | 778/820 [5:50:10<17:03, 24.38s/it]

 95%|█████████████████████████████████████████████████████████████████████████████████████████▎    | 779/820 [5:50:35<16:38, 24.36s/it]
{'loss': 1.8591, 'learning_rate': 7.917065803979995e-07, 'epoch': 9.5}


































 97%|███████████████████████████████████████████████████████████████████████████████████████████████▏  | 34/35 [02:00<00:03,  3.54s/it]
{'eval_loss': 2.1154298782348633, 'eval_runtime': 125.0559, 'eval_samples_per_second': 4.406, 'eval_steps_per_second': 0.28, 'epoch': 9.5}
/home/st-aleksandr-razin/.conda/envs/qc4qa/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 95%|█████████████████████████████████████████████████████████████████████████████████████████▍    | 780/820 [5:53:04<41:15, 61.88s/it]

 95%|█████████████████████████████████████████████████████████████████████████████████████████▌    | 781/820 [5:53:29<32:57, 50.69s/it]

 95%|█████████████████████████████████████████████████████████████████████████████████████████▋    | 782/820 [5:53:53<27:06, 42.80s/it]
{'loss': 2.032, 'learning_rate': 6.920390094970252e-07, 'epoch': 9.54}


 96%|█████████████████████████████████████████████████████████████████████████████████████████▊    | 784/820 [5:54:41<19:51, 33.09s/it]

 96%|█████████████████████████████████████████████████████████████████████████████████████████▉    | 785/820 [5:55:06<17:49, 30.54s/it]

 96%|██████████████████████████████████████████████████████████████████████████████████████████    | 786/820 [5:55:29<16:11, 28.56s/it]
{'loss': 1.8849, 'learning_rate': 5.695096443064652e-07, 'epoch': 9.59}


 96%|██████████████████████████████████████████████████████████████████████████████████████████▎   | 788/820 [5:56:18<14:05, 26.43s/it]
{'loss': 1.8759, 'learning_rate': 5.126935981488001e-07, 'epoch': 9.61}


 96%|██████████████████████████████████████████████████████████████████████████████████████████▌   | 790/820 [5:57:06<12:36, 25.21s/it]

 96%|██████████████████████████████████████████████████████████████████████████████████████████▋   | 791/820 [5:57:30<11:59, 24.82s/it]

 97%|██████████████████████████████████████████████████████████████████████████████████████████▊   | 792/820 [5:57:55<11:33, 24.76s/it]

 97%|██████████████████████████████████████████████████████████████████████████████████████████▉   | 793/820 [5:58:19<11:04, 24.62s/it]

 97%|███████████████████████████████████████████████████████████████████████████████████████████   | 794/820 [5:58:43<10:37, 24.53s/it]

 97%|███████████████████████████████████████████████████████████████████████████████████████████▏  | 795/820 [5:59:08<10:11, 24.47s/it]

 97%|███████████████████████████████████████████████████████████████████████████████████████████▏  | 796/820 [5:59:32<09:46, 24.44s/it]

 97%|███████████████████████████████████████████████████████████████████████████████████████████▎  | 797/820 [5:59:56<09:22, 24.44s/it]

 97%|███████████████████████████████████████████████████████████████████████████████████████████▍  | 798/820 [6:00:21<08:56, 24.38s/it]

 97%|███████████████████████████████████████████████████████████████████████████████████████████▌  | 799/820 [6:00:45<08:28, 24.24s/it]

 98%|███████████████████████████████████████████████████████████████████████████████████████████▋  | 800/820 [6:01:09<08:06, 24.32s/it]

 98%|███████████████████████████████████████████████████████████████████████████████████████████▊  | 801/820 [6:01:33<07:40, 24.21s/it]

 98%|███████████████████████████████████████████████████████████████████████████████████████████▉  | 802/820 [6:01:58<07:19, 24.44s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████████  | 803/820 [6:02:23<06:56, 24.50s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████████▏ | 804/820 [6:02:47<06:30, 24.42s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████████▎ | 805/820 [6:03:11<06:05, 24.38s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████████▍ | 806/820 [6:03:35<05:39, 24.27s/it]

 98%|████████████████████████████████████████████████████████████████████████████████████████████▌ | 807/820 [6:04:00<05:15, 24.29s/it]
{'loss': 1.9393, 'learning_rate': 1.2149743010237967e-07, 'epoch': 9.84}


 99%|████████████████████████████████████████████████████████████████████████████████████████████▋ | 809/820 [6:04:49<04:29, 24.46s/it]

 99%|████████████████████████████████████████████████████████████████████████████████████████████▊ | 810/820 [6:05:13<04:03, 24.32s/it]

 99%|████████████████████████████████████████████████████████████████████████████████████████████▉ | 811/820 [6:05:38<03:40, 24.53s/it]
{'loss': 1.844, 'learning_rate': 7.35102113454067e-08, 'epoch': 9.89}


 99%|█████████████████████████████████████████████████████████████████████████████████████████████▏| 813/820 [6:06:27<02:51, 24.55s/it]

 99%|█████████████████████████████████████████████████████████████████████████████████████████████▎| 814/820 [6:06:51<02:26, 24.45s/it]

 99%|█████████████████████████████████████████████████████████████████████████████████████████████▍| 815/820 [6:07:16<02:02, 24.47s/it]
{'loss': 2.0313, 'learning_rate': 3.75097126608881e-08, 'epoch': 9.94}


100%|█████████████████████████████████████████████████████████████████████████████████████████████▋| 817/820 [6:08:05<01:13, 24.48s/it]

100%|█████████████████████████████████████████████████████████████████████████████████████████████▊| 818/820 [6:08:29<00:48, 24.48s/it]

100%|█████████████████████████████████████████████████████████████████████████████████████████████▉| 819/820 [6:08:53<00:24, 24.33s/it]

100%|██████████████████████████████████████████████████████████████████████████████████████████████| 820/820 [6:09:06<00:00, 20.83s/it]
{'loss': 1.9073, 'learning_rate': 9.378307691776389e-09, 'epoch': 10.0}

































 94%|████████████████████████████████████████████████████████████████████████████████████████████▍     | 33/35 [01:54<00:07,  3.55s/it]

100%|██████████████████████████████████████████████████████████████████████████████████████████████| 820/820 [6:11:10<00:00, 20.83s/it][34m[1mwandb[39m[22m: Adding directory to artifact (/home/st-aleksandr-razin/workspace/SRC_QC4QA/QA_pipeline/artifacts/experiments/train-llama-7b-hf-Lora-System_Administration_and_DevOps-bs_16-lr_0.0001-m_l_1280-m_p_l_768-w_decay_0.4/checkpoint-820)... Done. 0.3s
100%|██████████████████████████████████████████████████████████████████████████████████████████████| 820/820 [6:11:11<00:00, 20.83s/it]

100%|██████████████████████████████████████████████████████████████████████████████████████████████| 820/820 [6:11:11<00:00, 27.16s/it]